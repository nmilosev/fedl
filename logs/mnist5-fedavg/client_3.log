DEBUG flower 2022-04-27 13:38:01,920 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2022-04-27 13:38:01,920 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2022-04-27 13:38:01,924 | app.py:61 | Opened (insecure) gRPC connection
Client CID: 3
[28016 28321 47294 53184]
[1344 3713 4197 4708]
Client 3 round 1 (before train) - Evaluate on 511 samples: Average loss: 2.3045, Accuracy: 4.89%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.316039				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.287088				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.311186				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.256845				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.266579				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.219471				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.227271				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.208490				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.210069				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.118514				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.151139				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.146489				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.138785				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.114387				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.051003				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.019827				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.068268				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.034097				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.932976				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.949624				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.982650				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.904153				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.878711				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.806490				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.777635				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.706493				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.745477				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.710749				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.590977				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.709785				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.645334				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.552106				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.552896				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.470284				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.565819				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.449776				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.514085				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.326617				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.334954				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.372050				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.415617				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.407289				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.298576				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.322116				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.153376				
 Client 3 round 1 returning params_prime of size 4800816  

Client 3 round 1 - Evaluate on 511 samples: Average loss: 0.4623, Accuracy: 86.69%

Client 3 round 2 (before train) - Evaluate on 511 samples: Average loss: 0.4623, Accuracy: 86.69%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.470191				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.433393				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.474480				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.579443				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.382309				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.710900				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.377108				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.549355				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.671085				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.573236				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.654885				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.665863				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.579785				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.601912				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.669834				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.621437				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.549447				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.638693				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.575348				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.496093				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.594291				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.455278				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.791158				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.488183				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.609562				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.604034				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.598544				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.498099				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.395124				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.516353				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.538240				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.719768				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.669036				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.603625				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.437284				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.529128				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.631214				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.651274				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.506169				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.640848				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.543486				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.543985				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.511902				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.418865				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.570684				
 Client 3 round 2 returning params_prime of size 4800816  

Client 3 round 2 - Evaluate on 511 samples: Average loss: 0.3211, Accuracy: 90.02%

Client 3 round 3 (before train) - Evaluate on 511 samples: Average loss: 0.3211, Accuracy: 90.02%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.366943				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.336112				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.406924				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.457441				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.401798				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.496520				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.466966				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.393691				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.576897				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.513064				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.537525				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.426552				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.477514				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.502684				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.373953				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.449599				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.276531				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.457729				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.611585				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.446684				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.311671				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.338641				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.505291				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.324228				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.490162				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.432052				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.427417				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.272115				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.531007				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.483925				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.366440				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.448898				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.329379				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.287335				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.491371				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.424518				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.368711				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.522759				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.291738				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.348337				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.334967				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.363855				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.273097				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.425754				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.304780				
 Client 3 round 3 returning params_prime of size 4800816  

Client 3 round 3 - Evaluate on 511 samples: Average loss: 0.2656, Accuracy: 91.00%

Client 3 round 4 (before train) - Evaluate on 511 samples: Average loss: 0.2656, Accuracy: 91.00%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.322171				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.379666				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.204117				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.657410				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.437970				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.315533				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.289665				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.177506				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.369086				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.304245				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.381210				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.364356				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.482282				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.380096				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.477400				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.237766				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.337739				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.459694				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.317659				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.434034				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.236316				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.337641				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.513759				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.282269				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.406467				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.267462				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.174775				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.537804				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.361417				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.387540				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.483606				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.358468				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.314028				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.485185				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.240335				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.189723				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.378462				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.449386				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.409647				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.389677				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.313141				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.305182				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.254457				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.322858				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.475680				
 Client 3 round 4 returning params_prime of size 4800816  

Client 3 round 4 - Evaluate on 511 samples: Average loss: 0.2267, Accuracy: 92.37%

Client 3 round 5 (before train) - Evaluate on 511 samples: Average loss: 0.2267, Accuracy: 92.37%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.312852				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.364734				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.358282				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.233201				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.457614				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.309401				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.416332				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.160846				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.267090				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.276326				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.334203				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.231975				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.134846				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.445868				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.260033				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.180711				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.271452				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.216602				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.224321				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.287595				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.565227				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.319178				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.370750				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.440194				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.433966				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.302845				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.470980				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.305299				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.145059				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.263755				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.366731				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.277335				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.396056				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.419598				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.231429				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.211875				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.251256				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.211913				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.420421				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.434460				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.214946				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.187728				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.195871				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.296865				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.275612				
 Client 3 round 5 returning params_prime of size 4800816  

Client 3 round 5 - Evaluate on 511 samples: Average loss: 0.2000, Accuracy: 93.35%

Client 3 round 6 (before train) - Evaluate on 511 samples: Average loss: 0.2000, Accuracy: 93.35%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.236480				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.242068				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.222659				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.593648				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.148406				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.414578				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.295695				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.326761				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.227334				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.327528				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.376225				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.161165				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.101222				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.182542				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.398990				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.163148				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.342966				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.330387				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.185736				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.223126				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.375589				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.345886				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.494079				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.300581				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.232865				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.217837				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.375630				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.289500				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.267204				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.311150				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.199169				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.327654				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.383094				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.350392				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.356729				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.258602				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.245640				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.281143				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.305866				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.242197				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.121305				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.323683				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.339970				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.194048				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.177753				
 Client 3 round 6 returning params_prime of size 4800816  

Client 3 round 6 - Evaluate on 511 samples: Average loss: 0.1802, Accuracy: 93.93%

Client 3 round 7 (before train) - Evaluate on 511 samples: Average loss: 0.1802, Accuracy: 93.93%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.367849				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.321432				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.282788				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.148714				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.343129				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.140439				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.393794				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.245096				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.177560				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.405178				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.355864				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.329589				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.214050				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.301091				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.131875				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.694908				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.305508				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.394262				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.215679				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.421931				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.259871				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.221825				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.230700				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.189816				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.350352				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.533707				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.198903				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.170017				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.515271				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.302574				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.323188				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.272289				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.254567				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.184667				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.308499				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.178843				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.266882				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.241417				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.189610				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.392702				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.308871				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.067812				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.260743				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.248803				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.295749				
 Client 3 round 7 returning params_prime of size 4800816  

Client 3 round 7 - Evaluate on 511 samples: Average loss: 0.1603, Accuracy: 95.11%

Client 3 round 8 (before train) - Evaluate on 511 samples: Average loss: 0.1603, Accuracy: 95.11%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.179760				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.210735				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.458323				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.406552				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.169744				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.169582				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.314092				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.217510				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.344923				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.202302				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.115658				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.083926				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.237069				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.148746				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.291740				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.287991				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.450974				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.202653				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.222649				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.343267				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.203349				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.182007				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.480163				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.133277				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.192877				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.264530				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.190930				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.249216				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.180860				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.345648				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.243967				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.275783				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.262320				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.104422				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.391169				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.282152				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.245679				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.296801				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.233914				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.259639				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.107540				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.311036				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.243198				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.327713				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.252757				
 Client 3 round 8 returning params_prime of size 4800816  

Client 3 round 8 - Evaluate on 511 samples: Average loss: 0.1451, Accuracy: 95.50%

Client 3 round 9 (before train) - Evaluate on 511 samples: Average loss: 0.1451, Accuracy: 95.50%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.278918				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.330671				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.136649				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.308668				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.298530				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.234258				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.268970				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.150444				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.188523				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.115517				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.377213				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.231766				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.165947				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.104982				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.141523				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.181337				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.272536				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.318298				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.236219				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.180894				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.436318				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.305754				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.167702				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.347006				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.242308				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.181186				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.280632				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.211933				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.123490				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.263703				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.127474				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.292214				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.189752				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.291325				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.422587				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.205141				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.191658				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.204650				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.284459				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.257556				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.349521				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.126574				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.190660				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.095347				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.175637				
 Client 3 round 9 returning params_prime of size 4800816  

Client 3 round 9 - Evaluate on 511 samples: Average loss: 0.1325, Accuracy: 96.09%

Client 3 round 10 (before train) - Evaluate on 511 samples: Average loss: 0.1325, Accuracy: 96.09%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.285335				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.255076				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.294281				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.167072				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.241128				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.266672				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.256678				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.184313				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.160777				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.285277				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.208779				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.287382				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.359796				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.126342				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.197125				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.247531				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.320154				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.078331				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.269350				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.170624				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.112575				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.300311				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.150635				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.305559				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.282405				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.160156				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.247640				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.280131				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.241499				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.103290				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.154550				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.350742				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.065753				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.130588				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.256493				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.199680				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.224722				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.326391				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.201822				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.172276				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.205004				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.187424				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.372908				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.392701				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.263703				
 Client 3 round 10 returning params_prime of size 4800816  

Client 3 round 10 - Evaluate on 511 samples: Average loss: 0.1223, Accuracy: 96.28%

Client 3 round 11 (before train) - Evaluate on 511 samples: Average loss: 0.1223, Accuracy: 96.28%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.216233				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.185455				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.083081				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.241509				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.291252				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.279641				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.221672				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.189092				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.234835				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.108561				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.081892				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.145483				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.221106				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.284695				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.073134				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.127352				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.263648				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.173198				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.183137				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.176855				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.232103				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.476441				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.234650				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.257368				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.124914				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.337047				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.349340				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.148501				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.264648				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.077749				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.220506				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.119315				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.206106				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.293987				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.259451				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.272885				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.169120				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.321191				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.200506				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.231853				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.199543				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.308433				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.264646				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.148482				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.331500				
 Client 3 round 11 returning params_prime of size 4800816  

Client 3 round 11 - Evaluate on 511 samples: Average loss: 0.1131, Accuracy: 97.06%

Client 3 round 12 (before train) - Evaluate on 511 samples: Average loss: 0.1131, Accuracy: 97.06%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.269512				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.150894				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.369933				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.081613				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.269373				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.220713				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.145367				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.195941				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.296171				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.297398				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.095636				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.165548				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.253082				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.263636				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.112829				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.136459				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.318157				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.174613				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.162144				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.252297				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.122116				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.397509				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.154288				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.189184				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.197901				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.109304				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.161076				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.276757				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.205383				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.220599				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.157689				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.362179				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.249625				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.439309				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.226702				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.163255				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.316083				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.069090				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.174715				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.369535				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.181486				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.181937				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.334857				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.299119				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.115685				
 Client 3 round 12 returning params_prime of size 4800816  

Client 3 round 12 - Evaluate on 511 samples: Average loss: 0.1061, Accuracy: 97.06%

Client 3 round 13 (before train) - Evaluate on 511 samples: Average loss: 0.1061, Accuracy: 97.06%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.275291				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.147291				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.145136				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.177400				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.352218				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.151172				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.149603				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.110930				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.157712				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.272667				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.175213				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.325121				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.214312				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.232907				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.178244				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.240722				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.184113				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.121640				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.074320				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.106267				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.214070				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.183837				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.118074				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.067318				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.167445				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.320656				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.142688				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.258308				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.108155				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.238870				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.253073				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.259164				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.107264				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.387425				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.265865				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.061858				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.160357				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.231101				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.201529				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.177439				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.126571				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.151078				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.219309				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.141483				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.180397				
 Client 3 round 13 returning params_prime of size 4800816  

Client 3 round 13 - Evaluate on 511 samples: Average loss: 0.0996, Accuracy: 97.26%

Client 3 round 14 (before train) - Evaluate on 511 samples: Average loss: 0.0996, Accuracy: 97.26%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.212656				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.072028				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.211096				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.108244				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.177825				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.148767				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.163617				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.082057				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.369106				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.177022				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.170994				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.450929				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.220411				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.154157				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.223961				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.144881				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.149191				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.071383				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.420903				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.157357				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.370618				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.289017				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.159495				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.102655				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.158515				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.130912				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.148567				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.195696				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.173385				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.157812				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.103746				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.119118				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.260760				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.154582				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.141816				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.266989				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.132273				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.186094				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.075067				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.139325				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.124091				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.134592				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.121065				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.243062				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.286624				
 Client 3 round 14 returning params_prime of size 4800816  

Client 3 round 14 - Evaluate on 511 samples: Average loss: 0.0937, Accuracy: 97.46%

Client 3 round 15 (before train) - Evaluate on 511 samples: Average loss: 0.0937, Accuracy: 97.46%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.204607				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.164713				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.116413				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.224025				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.253856				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.257627				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.293770				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.275317				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.251923				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.080432				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.123994				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.078077				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.188742				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.284636				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.495465				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.101128				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.170198				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.174072				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.116439				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.131869				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.072511				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.250593				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.099772				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.178971				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.256843				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.155372				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.248639				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.158876				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.303791				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.257340				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.120542				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.282669				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.113737				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.098073				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.418311				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.186387				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.127981				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.359385				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.119207				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.099965				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.196570				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.127795				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.103205				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.128826				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.151374				
 Client 3 round 15 returning params_prime of size 4800816  

Client 3 round 15 - Evaluate on 511 samples: Average loss: 0.0877, Accuracy: 97.46%

Client 3 round 16 (before train) - Evaluate on 511 samples: Average loss: 0.0877, Accuracy: 97.46%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.084646				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.220415				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.148862				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.146485				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.144651				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.192730				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.277441				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.096486				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.077858				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.119655				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.100392				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.235883				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.434208				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.125740				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.239663				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.130488				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.223422				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.226523				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.112641				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.164534				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.307177				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.038037				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.099991				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.331497				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.084925				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.085432				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.094581				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.170734				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.146976				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.134312				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.073357				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.302870				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.198674				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.317808				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.051202				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.451188				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.214316				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.042698				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.249907				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.209554				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.112728				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.238882				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.077349				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.109211				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.288792				
 Client 3 round 16 returning params_prime of size 4800816  

Client 3 round 16 - Evaluate on 511 samples: Average loss: 0.0847, Accuracy: 97.65%

Client 3 round 17 (before train) - Evaluate on 511 samples: Average loss: 0.0847, Accuracy: 97.65%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.054065				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.115959				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.132128				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.230860				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.212496				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.213845				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.094956				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.156527				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.112979				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.124879				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.101683				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.145100				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.086149				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.073754				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.176344				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.069833				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.022942				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.098630				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.113136				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.316959				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.084446				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.289301				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.098225				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.122929				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.224088				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.154605				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.155486				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.150387				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.143503				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.200318				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.224116				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.045349				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.144828				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.190963				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.218295				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.041702				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.128610				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.165874				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.171211				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.121751				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.093914				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.079787				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.093388				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.130439				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.278171				
 Client 3 round 17 returning params_prime of size 4800816  

Client 3 round 17 - Evaluate on 511 samples: Average loss: 0.0807, Accuracy: 97.65%

Client 3 round 18 (before train) - Evaluate on 511 samples: Average loss: 0.0807, Accuracy: 97.65%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.193291				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.346012				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.254793				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.125628				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.185560				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.136738				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.249933				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.271888				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.167409				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.198920				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.107085				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.121858				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.120997				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.133095				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.087739				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.163745				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.101185				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.228028				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.270459				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.090183				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.303257				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.149872				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.153138				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.091531				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.214328				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.246936				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.258776				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.059268				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.219670				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.243122				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.072408				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.093966				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.200333				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.313843				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.161939				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.212564				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.073073				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.079715				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.281054				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.123579				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.097264				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.133986				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.151763				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.058131				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.086144				
 Client 3 round 18 returning params_prime of size 4800816  

Client 3 round 18 - Evaluate on 511 samples: Average loss: 0.0767, Accuracy: 97.65%

Client 3 round 19 (before train) - Evaluate on 511 samples: Average loss: 0.0767, Accuracy: 97.65%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.107695				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.191222				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.145405				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.117005				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.051783				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.076800				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.139674				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.080937				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.205849				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.221410				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.083989				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.153475				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.138194				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.055747				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.038953				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.092821				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.186457				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.164142				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.203206				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.232091				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.266201				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.219953				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.189485				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.077591				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.039561				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.145800				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.196326				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.132971				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.102470				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.138693				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.105045				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.192555				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.221264				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.151931				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.174502				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.291420				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.090109				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.062926				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.083527				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.076984				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.161032				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.056672				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.347882				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.207874				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.176881				
 Client 3 round 19 returning params_prime of size 4800816  

Client 3 round 19 - Evaluate on 511 samples: Average loss: 0.0727, Accuracy: 97.65%

Client 3 round 20 (before train) - Evaluate on 511 samples: Average loss: 0.0727, Accuracy: 97.65%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.192427				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.093663				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.096164				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.153085				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.217346				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.112924				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.062115				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.201332				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.091272				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.214024				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.057340				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.064945				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.147168				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.125118				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.147852				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.322700				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.148987				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.052426				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.079401				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.308539				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.317772				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.115160				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.166740				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.061588				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.087314				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.203114				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.092834				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.070812				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.182889				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.169361				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.104422				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.157152				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.081867				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.152883				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.190451				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.119185				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.158046				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.139875				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.053731				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.169355				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.212781				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.374004				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.142788				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.226364				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.096787				DEBUG flower 2022-04-27 15:10:22,104 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-04-27 15:10:22,104 | app.py:72 | Disconnect and shut down

 Client 3 round 20 returning params_prime of size 4800816  

Client 3 round 20 - Evaluate on 511 samples: Average loss: 0.0709, Accuracy: 97.65%

