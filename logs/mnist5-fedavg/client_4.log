DEBUG flower 2022-04-27 13:38:02,002 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2022-04-27 13:38:02,003 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2022-04-27 13:38:02,005 | app.py:61 | Opened (insecure) gRPC connection
Client CID: 4
[28016 28321 47294 53184]
[1344 3713 4197 4708]
Client 4 round 1 (before train) - Evaluate on 5292 samples: Average loss: 2.2971, Accuracy: 10.36%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.312125				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.306586				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.280937				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.264929				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.258449				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.236809				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.236530				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.189686				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.178515				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.182887				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.173123				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.147094				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.111771				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.081193				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.046893				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.050206				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.057713				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.967517				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.943358				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.852918				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.955094				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.819350				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.756762				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.693186				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.775223				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.729891				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.660726				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.692645				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.600500				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.610809				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.428034				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.498859				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.596623				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.456084				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.413300				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.359933				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.268295				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.446854				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.308637				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.391375				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.228327				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.342021				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.236804				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.189301				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.423077				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.027664				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.080321				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.195626				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.132302				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.064974				
 Client 4 round 1 returning params_prime of size 4800816  

Client 4 round 1 - Evaluate on 5292 samples: Average loss: 0.4196, Accuracy: 89.95%

Client 4 round 2 (before train) - Evaluate on 5292 samples: Average loss: 0.4196, Accuracy: 89.95%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.600633				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.646253				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.640424				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.688697				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.575519				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.512807				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.436918				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.589819				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.596530				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.550441				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.649692				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.510280				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.511802				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.472026				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.480509				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.583566				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.720437				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.576522				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.552724				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.582882				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.754455				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.445727				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.426597				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.529683				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.604208				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.640796				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.793353				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.511002				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.315772				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.540905				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.532797				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.621107				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.469623				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.420117				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.389296				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.647934				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.482976				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.543872				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.478522				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.542305				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.354048				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.516300				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.690980				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.570009				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.428247				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.541859				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.412898				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.348890				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.506503				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.279055				
 Client 4 round 2 returning params_prime of size 4800816  

Client 4 round 2 - Evaluate on 5292 samples: Average loss: 0.2859, Accuracy: 92.04%

Client 4 round 3 (before train) - Evaluate on 5292 samples: Average loss: 0.2859, Accuracy: 92.04%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.443400				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.452591				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.436935				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.426115				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.567701				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.341213				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.295836				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.334180				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.409073				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.299248				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.342187				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.559812				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.352754				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.374664				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.514323				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.305871				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.440647				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.450769				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.482452				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.516004				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.428735				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.329528				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.402924				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.532930				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.311340				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.680051				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.343746				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.355363				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.422364				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.333652				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.320882				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.444099				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.394922				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.602941				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.418680				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.326246				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.334505				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.403054				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.366598				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.443199				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.285576				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.498418				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.280160				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.326574				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.467606				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.397554				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.261248				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.266497				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.307676				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.575047				
 Client 4 round 3 returning params_prime of size 4800816  

Client 4 round 3 - Evaluate on 5292 samples: Average loss: 0.2406, Accuracy: 92.78%

Client 4 round 4 (before train) - Evaluate on 5292 samples: Average loss: 0.2406, Accuracy: 92.78%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.613770				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.210402				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.294030				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.483736				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.271850				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.236372				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.364633				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.503966				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.424452				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.517747				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.305830				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.207114				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.488752				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.206563				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.494917				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.325651				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.308356				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.192852				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.254857				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.501212				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.414419				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.145016				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.342601				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.325980				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.301349				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.434324				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.295388				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.381966				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.483432				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.300979				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.425999				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.453382				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.342922				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.232688				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.274758				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.275486				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.312022				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.283750				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.484271				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.305932				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.180166				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.286843				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.416679				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.399968				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.207070				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.295917				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.501502				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.291098				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.342720				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.308742				
 Client 4 round 4 returning params_prime of size 4800816  

Client 4 round 4 - Evaluate on 5292 samples: Average loss: 0.2126, Accuracy: 93.56%

Client 4 round 5 (before train) - Evaluate on 5292 samples: Average loss: 0.2126, Accuracy: 93.56%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.272207				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.348281				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.326226				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.383220				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.345603				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.304536				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.437111				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.329044				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.407931				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.314185				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.527303				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.379067				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.186756				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.401927				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.207945				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.461454				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.339152				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.340416				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.238729				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.457747				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.287621				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.285136				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.341160				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.342495				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.470237				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.499651				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.264686				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.452695				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.307085				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.448724				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.255031				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.276384				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.204954				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.207453				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.352948				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.420664				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.380656				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.209005				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.476589				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.359042				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.435363				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.187505				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.461949				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.393027				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.471388				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.475551				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.359496				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.211238				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.164127				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.318263				
 Client 4 round 5 returning params_prime of size 4800816  

Client 4 round 5 - Evaluate on 5292 samples: Average loss: 0.1911, Accuracy: 94.39%

Client 4 round 6 (before train) - Evaluate on 5292 samples: Average loss: 0.1911, Accuracy: 94.39%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.447251				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.224110				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.234460				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.300073				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.522377				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.451727				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.457947				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.280097				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.291979				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.477507				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.248163				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.306366				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.186274				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.276489				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.196232				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.520399				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.164805				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.266714				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.340862				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.326981				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.188681				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.411193				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.297820				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.143914				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.343200				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.200130				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.171769				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.410029				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.302641				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.189091				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.331421				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.237518				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.298129				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.262389				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.310366				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.253209				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.504250				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.193614				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.245560				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.351578				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.169673				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.438597				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.362527				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.329473				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.290883				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.392912				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.153249				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.169903				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.143024				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.330049				
 Client 4 round 6 returning params_prime of size 4800816  

Client 4 round 6 - Evaluate on 5292 samples: Average loss: 0.1756, Accuracy: 94.94%

Client 4 round 7 (before train) - Evaluate on 5292 samples: Average loss: 0.1756, Accuracy: 94.94%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.201494				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.521631				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.302838				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.340618				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.316568				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.174134				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.271026				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.283422				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.196666				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.124107				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.335282				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.226924				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.209777				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.280045				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.262951				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.203679				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.297877				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.395473				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.227739				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.175840				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.109232				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.168634				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.221317				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.275989				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.462273				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.298395				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.200910				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.141655				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.189672				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.265832				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.165780				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.200826				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.423818				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.435508				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.132987				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.321889				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.151608				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.310211				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.149156				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.195339				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.195451				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.226398				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.375045				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.111519				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.279938				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.395708				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.209340				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.169118				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.311570				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.372001				
 Client 4 round 7 returning params_prime of size 4800816  

Client 4 round 7 - Evaluate on 5292 samples: Average loss: 0.1639, Accuracy: 95.16%

Client 4 round 8 (before train) - Evaluate on 5292 samples: Average loss: 0.1639, Accuracy: 95.16%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.212356				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.254023				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.146558				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.204353				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.326423				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.358031				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.269694				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.198139				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.211717				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.272185				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.335801				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.171695				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.185963				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.260208				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.213616				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.434837				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.148748				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.239737				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.289515				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.329682				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.226257				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.374658				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.219607				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.199296				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.245031				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.167484				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.148105				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.256600				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.421032				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.144400				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.221183				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.218376				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.287095				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.372051				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.252693				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.141189				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.398333				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.063553				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.194190				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.155802				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.187959				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.299858				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.201858				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.160661				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.186862				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.324853				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.223057				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.211700				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.199488				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.267586				
 Client 4 round 8 returning params_prime of size 4800816  

Client 4 round 8 - Evaluate on 5292 samples: Average loss: 0.1516, Accuracy: 95.56%

Client 4 round 9 (before train) - Evaluate on 5292 samples: Average loss: 0.1516, Accuracy: 95.56%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.102639				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.174432				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.189406				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.345439				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.360465				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.141472				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.388998				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.226810				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.439509				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.202512				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.055981				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.096191				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.136004				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.311933				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.076433				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.368439				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.184270				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.203968				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.180491				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.208893				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.264196				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.292742				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.135808				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.201564				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.099846				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.228861				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.196523				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.192776				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.163464				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.189940				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.270431				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.255258				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.457721				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.085459				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.372579				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.244808				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.297135				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.207726				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.118481				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.556779				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.347727				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.087866				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.192848				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.228534				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.350517				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.243887				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.282695				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.318756				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.314492				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.274712				
 Client 4 round 9 returning params_prime of size 4800816  

Client 4 round 9 - Evaluate on 5292 samples: Average loss: 0.1436, Accuracy: 95.90%

Client 4 round 10 (before train) - Evaluate on 5292 samples: Average loss: 0.1436, Accuracy: 95.90%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.319304				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.232461				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.435000				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.107613				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.127653				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.215973				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.161145				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.284950				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.278010				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.239260				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.311557				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.330921				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.152191				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.145739				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.142799				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.268462				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.208281				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.140115				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.208996				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.217538				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.306668				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.267337				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.235121				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.194918				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.200443				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.431066				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.501193				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.170074				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.244801				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.231894				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.156484				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.089738				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.173920				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.119355				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.056010				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.250074				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.156841				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.164735				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.173620				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.371835				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.377242				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.086784				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.152776				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.106888				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.185776				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.379684				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.131663				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.287041				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.173367				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.191542				
 Client 4 round 10 returning params_prime of size 4800816  

Client 4 round 10 - Evaluate on 5292 samples: Average loss: 0.1340, Accuracy: 95.99%

Client 4 round 11 (before train) - Evaluate on 5292 samples: Average loss: 0.1340, Accuracy: 95.99%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.267169				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.394358				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.424493				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.142576				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.262640				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.132820				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.201066				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.184245				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.242970				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.308715				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.194233				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.376295				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.186207				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.133778				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.095635				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.134093				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.368475				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.290988				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.204062				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.312976				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.291104				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.168463				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.112941				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.154670				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.230549				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.312403				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.092858				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.146257				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.369577				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.152559				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.262754				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.210360				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.116603				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.244561				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.128870				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.118932				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.121444				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.287644				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.183582				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.184543				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.172449				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.070241				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.405917				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.130931				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.143707				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.278691				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.158655				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.153385				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.192161				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.317392				
 Client 4 round 11 returning params_prime of size 4800816  

Client 4 round 11 - Evaluate on 5292 samples: Average loss: 0.1275, Accuracy: 96.18%

Client 4 round 12 (before train) - Evaluate on 5292 samples: Average loss: 0.1275, Accuracy: 96.18%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.189504				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.213640				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.289170				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.099163				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.104737				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.231041				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.187620				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.110547				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.167368				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.289822				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.286034				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.160098				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.083313				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.324031				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.087439				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.315843				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.139493				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.288221				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.394471				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.314181				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.125865				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.104680				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.149950				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.329503				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.119279				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.149747				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.229236				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.224676				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.243608				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.153917				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.181542				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.128766				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.137586				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.271872				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.148447				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.091904				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.342506				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.194456				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.217901				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.108898				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.336595				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.177174				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.084208				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.268217				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.180037				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.180106				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.134487				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.089146				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.292755				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.315343				
 Client 4 round 12 returning params_prime of size 4800816  

Client 4 round 12 - Evaluate on 5292 samples: Average loss: 0.1212, Accuracy: 96.37%

Client 4 round 13 (before train) - Evaluate on 5292 samples: Average loss: 0.1212, Accuracy: 96.37%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.232247				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.155847				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.175945				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.187046				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.220302				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.202677				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.063267				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.202898				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.238827				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.181598				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.255949				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.235456				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.103199				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.270712				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.208131				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.164008				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.149858				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.204664				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.130075				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.093270				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.101648				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.167677				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.393276				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.180013				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.268212				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.142791				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.129182				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.153794				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.142180				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.135757				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.113081				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.118925				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.322440				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.272730				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.209999				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.189156				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.255740				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.118243				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.227576				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.135857				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.073861				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.134429				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.355146				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.267133				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.071254				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.176548				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.162852				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.100383				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.140584				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.141438				
 Client 4 round 13 returning params_prime of size 4800816  

Client 4 round 13 - Evaluate on 5292 samples: Average loss: 0.1158, Accuracy: 96.54%

Client 4 round 14 (before train) - Evaluate on 5292 samples: Average loss: 0.1158, Accuracy: 96.54%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.083747				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.185570				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.152664				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.155767				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.163582				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.157607				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.184642				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.305438				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.159812				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.113876				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.106937				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.078568				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.312783				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.216885				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.217117				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.191388				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.300760				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.096782				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.204012				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.074788				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.188881				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.086766				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.080895				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.155434				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.116059				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.126795				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.122512				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.175715				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.123066				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.114520				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.242138				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.161043				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.226296				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.140796				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.172171				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.224607				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.083304				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.357031				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.208619				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.164833				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.180908				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.126703				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.311865				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.221892				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.177793				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.182233				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.212091				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.077100				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.272267				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.169572				
 Client 4 round 14 returning params_prime of size 4800816  

Client 4 round 14 - Evaluate on 5292 samples: Average loss: 0.1104, Accuracy: 96.71%

Client 4 round 15 (before train) - Evaluate on 5292 samples: Average loss: 0.1104, Accuracy: 96.71%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.105170				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.440458				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.111261				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.262716				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.183112				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.072572				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.172857				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.190561				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.106274				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.152063				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.194205				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.242249				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.291685				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.187908				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.070982				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.107873				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.143821				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.069198				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.331541				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.099716				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.065473				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.106518				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.112373				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.156228				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.096261				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.366874				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.143420				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.150549				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.075115				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.297499				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.163429				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.141506				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.199289				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.192147				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.063624				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.134805				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.139846				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.358388				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.098291				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.210306				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.264581				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.216725				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.240478				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.314404				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.140433				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.382498				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.118183				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.110860				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.062218				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.180697				
 Client 4 round 15 returning params_prime of size 4800816  

Client 4 round 15 - Evaluate on 5292 samples: Average loss: 0.1058, Accuracy: 96.71%

Client 4 round 16 (before train) - Evaluate on 5292 samples: Average loss: 0.1058, Accuracy: 96.71%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.172083				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.258260				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.101115				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.091689				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.084185				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.123517				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.172987				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.176261				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.106246				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.199592				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.103262				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.197129				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.184852				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.119307				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.143507				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.230600				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.188969				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.106841				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.255890				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.173886				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.205291				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.223745				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.228698				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.182396				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.128045				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.195943				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.125677				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.223757				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.125350				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.067891				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.154030				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.127317				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.214030				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.289717				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.191141				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.175105				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.108193				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.214508				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.074353				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.293472				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.106447				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.172664				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.047438				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.194952				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.108702				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.175153				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.177334				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.154425				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.316984				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.180085				
 Client 4 round 16 returning params_prime of size 4800816  

Client 4 round 16 - Evaluate on 5292 samples: Average loss: 0.1014, Accuracy: 96.92%

Client 4 round 17 (before train) - Evaluate on 5292 samples: Average loss: 0.1014, Accuracy: 96.92%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.243239				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.131875				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.106146				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.048953				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.111679				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.314988				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.193500				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.113723				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.281124				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.263154				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.330478				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.273622				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.114127				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.182416				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.160634				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.264445				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.199783				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.309308				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.067684				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.216668				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.267084				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.101191				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.140466				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.235834				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.406162				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.123525				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.150255				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.191474				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.045585				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.130348				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.160075				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.249160				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.141355				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.107979				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.086672				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.216403				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.105905				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.221161				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.089000				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.197190				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.172732				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.130432				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.117527				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.092734				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.227435				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.196055				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.096807				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.136956				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.187898				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.135967				
 Client 4 round 17 returning params_prime of size 4800816  

Client 4 round 17 - Evaluate on 5292 samples: Average loss: 0.0985, Accuracy: 96.88%

Client 4 round 18 (before train) - Evaluate on 5292 samples: Average loss: 0.0985, Accuracy: 96.88%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.091206				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.129980				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.081354				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.368331				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.217052				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.071349				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.154307				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.095386				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.107791				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.075153				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.203264				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.091340				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.151838				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.154353				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.080902				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.095885				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.193533				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.094943				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.161983				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.140826				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.045058				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.151999				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.106965				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.131307				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.116242				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.166671				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.117295				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.228928				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.070027				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.057918				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.124854				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.133500				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.188801				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.227732				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.337308				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.152548				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.130703				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.239763				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.211183				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.223155				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.212498				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.347632				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.089941				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.132171				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.178078				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.077909				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.155465				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.108903				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.157983				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.127592				
 Client 4 round 18 returning params_prime of size 4800816  

Client 4 round 18 - Evaluate on 5292 samples: Average loss: 0.0931, Accuracy: 97.07%

Client 4 round 19 (before train) - Evaluate on 5292 samples: Average loss: 0.0931, Accuracy: 97.07%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.220456				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.159964				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.130940				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.151751				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.128092				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.130019				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.103972				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.239401				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.158420				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.177467				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.082136				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.237255				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.046893				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.072168				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.226264				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.246902				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.098832				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.160857				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.151570				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.200482				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.214346				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.078585				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.058202				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.081345				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.160084				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.121742				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.085411				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.350064				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.103759				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.161057				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.255529				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.197597				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.292701				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.072467				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.306610				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.075645				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.141381				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.036358				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.152514				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.232761				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.038308				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.159074				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.233624				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.175056				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.192391				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.056822				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.073980				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.373013				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.146411				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.226752				
 Client 4 round 19 returning params_prime of size 4800816  

Client 4 round 19 - Evaluate on 5292 samples: Average loss: 0.0898, Accuracy: 97.20%

Client 4 round 20 (before train) - Evaluate on 5292 samples: Average loss: 0.0898, Accuracy: 97.20%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.068905				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.118993				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.154726				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.173038				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.037125				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.190077				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.048405				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.112021				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.232115				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.130873				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.144906				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.048939				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.217503				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.185970				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.137427				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.070708				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.094589				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.043445				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.052114				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.199512				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.068530				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.042931				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.090763				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.115109				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.156469				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.100217				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.201204				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.236963				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.091072				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.197147				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.194026				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.200385				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.167318				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.170529				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.086259				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.063073				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.131333				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.296441				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.153985				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.082895				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.066148				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.179810				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.135525				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.195751				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.097507				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.066214				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.395782				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.049923				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.109752				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.048832				DEBUG flower 2022-04-27 15:10:22,107 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-04-27 15:10:22,107 | app.py:72 | Disconnect and shut down

 Client 4 round 20 returning params_prime of size 4800816  

Client 4 round 20 - Evaluate on 5292 samples: Average loss: 0.0873, Accuracy: 97.24%

