DEBUG flower 2022-04-17 22:38:52,256 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2022-04-17 22:38:52,256 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2022-04-17 22:38:52,261 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2022-04-17 22:38:52,261 | connection.py:36 | ChannelConnectivity.READY
Client CID: 3
[28016 28321 47294 53184]
[1344 3713 4197 4708]
Client 3 round 1 (before train) - Evaluate on 511 samples: Average loss: 2.3069, Accuracy: 8.02%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.294900				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.276658				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.277479				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.280177				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.260267				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.273108				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.249054				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.224023				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.216469				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.205337				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.210444				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.200161				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.187119				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.167028				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.136894				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.174767				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.111940				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.152505				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.105537				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.064301				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.106157				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.040734				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.079392				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.961541				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.996718				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.973022				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.021949				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.976175				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.973069				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.871879				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.886515				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.892881				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.843492				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.823058				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.954585				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.763116				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.845269				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.808802				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.718813				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.637407				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.848904				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.630673				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.736521				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.679813				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.797354				Client 3 should_send_params: True 


 Client 3 round 1 returning params_prime of size 4800816  

Client 3 round 1 - Evaluate on 511 samples: Average loss: 0.8045, Accuracy: 74.56%

Client 3 round 2 (before train) - Evaluate on 511 samples: Average loss: 0.8045, Accuracy: 74.56%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.761221				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.860902				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.779804				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.810111				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.090389				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.792005				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.909665				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.860501				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.919414				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.900641				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.732662				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.691106				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 1.025203				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.786408				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 1.089655				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.923700				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.887380				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.968747				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.019985				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.800425				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.831677				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.794987				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.652521				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.846923				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.914356				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.804121				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.955979				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.924546				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.970065				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.840170				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.743275				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.601229				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.817816				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.881715				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.762181				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.963031				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.759576				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.873834				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.878887				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.719425				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.238712				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.930062				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.720898				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.662510				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.867429				Client 3 should_send_params: True 


 Client 3 round 2 returning params_prime of size 4800816  

Client 3 round 2 - Evaluate on 511 samples: Average loss: 0.7021, Accuracy: 74.36%

Client 3 round 3 (before train) - Evaluate on 511 samples: Average loss: 0.7021, Accuracy: 74.36%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.814396				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.659598				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.645114				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.959384				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.800811				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.793505				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.962154				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.911394				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.698492				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.822346				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.943451				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.718635				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.939946				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.697899				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.648487				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.851069				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.996240				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.607269				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.778730				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.657931				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.741884				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.628750				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.661956				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.872423				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.025403				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.783100				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.821814				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.685252				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.897231				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.690131				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.784765				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.715220				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.767382				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.631212				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.753747				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.917726				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.835009				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.827608				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.706405				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.779431				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.725753				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.671583				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.641654				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.944242				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.802297				Client 3 should_send_params: True 


 Client 3 round 3 returning params_prime of size 4800816  

Client 3 round 3 - Evaluate on 511 samples: Average loss: 0.6601, Accuracy: 75.15%

Client 3 round 4 (before train) - Evaluate on 511 samples: Average loss: 0.6601, Accuracy: 75.15%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.679110				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.802850				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.728056				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.906732				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.664155				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.820610				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.872621				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.681833				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.698503				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.773332				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.772766				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.660132				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.547552				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.793796				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.551263				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.960820				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.641399				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.929024				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.616571				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.485730				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.760865				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.694618				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.743802				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.743993				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.747627				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.888920				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.742538				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.740477				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.821800				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.590671				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.643507				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.625135				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.843761				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.725894				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.704221				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.804811				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.646273				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.580326				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.606752				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.796085				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.480903				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.939344				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.712390				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.605876				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.753238				Client 3 should_send_params: True 


 Client 3 round 4 returning params_prime of size 4800816  

Client 3 round 4 - Evaluate on 511 samples: Average loss: 0.6294, Accuracy: 76.13%

Client 3 round 5 (before train) - Evaluate on 511 samples: Average loss: 0.6294, Accuracy: 76.13%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.599659				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.743924				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.777158				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.839294				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.569850				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.659570				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.650605				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.689098				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.573149				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.935271				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.422486				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.717503				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.720967				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.988798				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.537531				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.584543				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.711833				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.795607				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.764840				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.776598				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.821785				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.816810				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.464740				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.550316				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.724882				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.790709				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.771574				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.707961				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.754250				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.810616				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.690797				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.654425				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.628601				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.799774				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.689903				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.623446				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.596319				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.696722				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.795459				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.776270				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.760501				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.630356				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.704027				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.782682				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.828635				Client 3 should_send_params: True 


 Client 3 round 5 returning params_prime of size 4800816  

Client 3 round 5 - Evaluate on 511 samples: Average loss: 0.6134, Accuracy: 77.30%

Client 3 round 6 (before train) - Evaluate on 511 samples: Average loss: 0.6134, Accuracy: 77.30%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.890242				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.639587				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.586182				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.723884				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.615871				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.593864				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.453059				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.809372				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.626589				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.605010				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.810398				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.554267				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.681806				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.726243				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.689120				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.649892				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.719686				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.575786				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.741862				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.443826				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.709268				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.727688				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.542829				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.608864				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.676712				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.618965				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.727840				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.683602				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.787612				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.840813				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.657946				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.551354				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.727174				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.724641				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.483168				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.613420				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.579379				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.681597				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.622751				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.698899				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.727060				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.666551				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.596340				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.749470				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.453767				Client 3 should_send_params: True 


 Client 3 round 6 returning params_prime of size 4800816  

Client 3 round 6 - Evaluate on 511 samples: Average loss: 0.5925, Accuracy: 77.30%

Client 3 round 7 (before train) - Evaluate on 511 samples: Average loss: 0.5925, Accuracy: 77.30%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.711925				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.706381				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.778576				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.584545				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.545823				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.674188				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.778185				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.593581				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.653643				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.593017				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.607609				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.671746				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.612223				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.654607				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.725077				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.506408				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.713299				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.916801				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.706285				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.772307				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.829898				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.694663				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.704320				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.820130				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.546711				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.694527				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.864572				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.568303				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.829956				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.594888				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.790395				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.806458				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.677844				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.661132				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.548150				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.679814				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.598844				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.474189				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.353656				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.750699				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.580508				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.788142				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.702120				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.625560				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.618120				Client 3 should_send_params: True 


 Client 3 round 7 returning params_prime of size 4800816  

Client 3 round 7 - Evaluate on 511 samples: Average loss: 0.5768, Accuracy: 77.89%

Client 3 round 8 (before train) - Evaluate on 511 samples: Average loss: 0.5768, Accuracy: 77.89%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.771743				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.557466				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.745567				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.601008				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.481169				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.824307				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.562037				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.724041				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.618234				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.527778				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.559768				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.893590				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.519270				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.587535				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.568656				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.645010				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.612837				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.796236				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.704156				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.484408				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.619791				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.596000				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.639388				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.452847				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.594692				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.810869				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.730024				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.456185				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.841787				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.775857				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.497632				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.664427				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.601190				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.498696				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.616076				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.873711				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.386705				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.653067				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.553137				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.665534				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.636050				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.631020				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.571698				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.681382				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.664117				Client 3 should_send_params: False 


 Client 3 round 8 returning params_prime of size 169  

Client 3 round 8 - Evaluate on 511 samples: Average loss: 0.5647, Accuracy: 79.26%

Client 3 round 9 (before train) - Evaluate on 511 samples: Average loss: 0.5647, Accuracy: 79.26%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.919158				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.664932				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.832797				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.538803				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.730915				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.499341				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.535396				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.818210				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.577908				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.579337				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.446332				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.570489				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.715063				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.510607				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.956132				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.423029				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.456296				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.558962				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.581201				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.542279				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.827548				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.513456				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.571007				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.713004				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.641499				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.691470				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.673483				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.498995				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.575746				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.873085				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.580389				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.628341				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.515632				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.439209				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.770156				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.659238				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.606223				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.612559				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.604025				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.643056				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.715318				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.602614				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.429936				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.667722				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.473844				Client 3 should_send_params: True 


 Client 3 round 9 returning params_prime of size 4800816  

Client 3 round 9 - Evaluate on 511 samples: Average loss: 0.5530, Accuracy: 79.45%

Client 3 round 10 (before train) - Evaluate on 511 samples: Average loss: 0.5530, Accuracy: 79.45%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.531885				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.368287				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.549572				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.751687				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.766854				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.751978				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.634434				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.655379				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.538322				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.550074				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.643718				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.835836				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.569042				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.626723				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.584386				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.584729				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.559614				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.645556				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.617427				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.525056				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.708746				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.594875				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.574149				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.487621				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.544886				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.614808				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.542127				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.595208				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.481701				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.614828				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.801746				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.688200				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.728098				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.562913				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.761346				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.523160				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.615924				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.694302				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.767120				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.764677				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.569001				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.632918				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.668329				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.590685				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.517323				Client 3 should_send_params: False 


 Client 3 round 10 returning params_prime of size 169  

Client 3 round 10 - Evaluate on 511 samples: Average loss: 0.5432, Accuracy: 79.45%

Client 3 round 11 (before train) - Evaluate on 511 samples: Average loss: 0.5432, Accuracy: 79.45%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.620479				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.677887				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.758669				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.636367				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.533357				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.584267				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.538251				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.571385				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.610219				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.495304				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.719498				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.401554				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.621866				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.603410				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.577711				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.668402				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.693546				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.612564				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.541925				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.584011				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.587294				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.499436				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.702666				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.684810				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.346499				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.534890				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.653001				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.398467				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.749679				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.525706				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.879426				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.690435				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.608553				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.731088				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.541380				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.547528				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.543332				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.473669				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.635247				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.614720				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.402952				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.572759				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.599670				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.634170				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.528450				Client 3 should_send_params: True 


 Client 3 round 11 returning params_prime of size 4800816  

Client 3 round 11 - Evaluate on 511 samples: Average loss: 0.5356, Accuracy: 80.04%

Client 3 round 12 (before train) - Evaluate on 511 samples: Average loss: 0.5356, Accuracy: 80.04%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.618846				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.554283				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.536607				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.392279				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.790350				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.614759				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.562604				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.581342				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.567743				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.420755				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.548410				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.444638				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.622685				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.566464				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.551145				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.713030				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.650268				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.596590				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.538757				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.586602				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.736007				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.668948				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.495678				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.774758				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.502676				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.745631				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.588106				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.638246				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.509133				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.473954				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.470029				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.634134				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.465312				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.633508				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.623349				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.513260				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.544583				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.884292				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.482129				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.685835				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.668952				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.416810				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.506126				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.631305				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.520510				Client 3 should_send_params: True 


 Client 3 round 12 returning params_prime of size 4800816  

Client 3 round 12 - Evaluate on 511 samples: Average loss: 0.5278, Accuracy: 80.82%

Client 3 round 13 (before train) - Evaluate on 511 samples: Average loss: 0.5278, Accuracy: 80.82%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.603201				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.632246				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.554228				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.686710				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.522162				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.574245				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.605560				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.559648				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.676602				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.594708				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.562669				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.654059				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.573812				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.609846				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.633257				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.609904				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.583840				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.394030				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.517040				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.614608				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.528204				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.695206				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.637079				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.428568				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.587835				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.566875				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.549211				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.780469				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.542873				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.501422				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.522780				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.407810				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.632091				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.680619				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.554386				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.503951				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.519487				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.533878				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.548993				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.497805				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.499865				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.473820				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.708118				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.594801				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.409568				Client 3 should_send_params: True 


 Client 3 round 13 returning params_prime of size 4800816  

Client 3 round 13 - Evaluate on 511 samples: Average loss: 0.5193, Accuracy: 79.65%

Client 3 round 14 (before train) - Evaluate on 511 samples: Average loss: 0.5193, Accuracy: 79.65%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.565455				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.523742				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.477543				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.496967				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.509683				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.644544				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.541752				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.550503				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.713920				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.511285				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.653379				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.504532				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.393719				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.440745				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.684120				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.389359				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.470803				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.402254				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.584652				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.410807				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.600149				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.562720				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.464239				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.426905				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.532982				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.654683				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.442689				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.408544				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.655409				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.626327				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.622987				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.409479				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.630781				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.565718				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.514665				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.602129				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.451934				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.730791				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.525580				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.517075				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.646226				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.726975				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.378834				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.588323				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.500512				Client 3 should_send_params: False 


 Client 3 round 14 returning params_prime of size 169  

Client 3 round 14 - Evaluate on 511 samples: Average loss: 0.5103, Accuracy: 81.02%

Client 3 round 15 (before train) - Evaluate on 511 samples: Average loss: 0.5103, Accuracy: 81.02%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.647178				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.503761				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.460146				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.398119				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.477714				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.584819				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.644809				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.450762				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.587361				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.543235				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.639570				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.567538				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.527322				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.770320				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.553513				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.518308				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.587987				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.488596				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.536932				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.357863				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.433412				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.544303				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.460807				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.458552				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.458003				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.572782				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.598680				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.525734				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.328175				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.560616				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.550769				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.637498				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.458846				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.381800				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.519012				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.607373				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.629684				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.460758				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.464569				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.476685				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.457399				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.335129				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.559458				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.703130				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.504750				Client 3 should_send_params: True 


 Client 3 round 15 returning params_prime of size 4800816  

Client 3 round 15 - Evaluate on 511 samples: Average loss: 0.5070, Accuracy: 80.82%

Client 3 round 16 (before train) - Evaluate on 511 samples: Average loss: 0.5070, Accuracy: 80.82%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.490967				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.486161				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.649015				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.641044				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.548217				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.629918				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.526855				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.547882				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.470654				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.386235				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.597866				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.519968				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.568678				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.495037				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.357720				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.526876				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.369601				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.337833				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.425719				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.572934				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.611180				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.407818				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.464779				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.459356				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.553763				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.520006				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.687572				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.640747				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.434021				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.347043				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.349894				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.603273				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.659323				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.632792				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.442500				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.341737				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.595294				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.568254				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.570387				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.435318				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.604945				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.421260				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.473410				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.456141				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.374090				Client 3 should_send_params: True 


 Client 3 round 16 returning params_prime of size 4800816  

Client 3 round 16 - Evaluate on 511 samples: Average loss: 0.4997, Accuracy: 80.63%

Client 3 round 17 (before train) - Evaluate on 511 samples: Average loss: 0.4997, Accuracy: 80.63%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.438670				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.536654				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.484088				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.406441				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.300009				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.470727				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.572206				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.598357				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.364046				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.559363				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.490344				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.705052				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.684797				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.664328				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.632735				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.464586				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.418041				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.435669				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.563417				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.441870				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.556023				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.423408				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.719637				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.472413				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.759245				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.546227				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.644628				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.456760				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.586890				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.565215				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.481142				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.589868				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.589883				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.564454				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.517255				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.594526				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.649584				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.457871				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.574571				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.447850				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.658100				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.500908				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.638806				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.488435				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.629336				Client 3 should_send_params: True 


 Client 3 round 17 returning params_prime of size 4800816  

Client 3 round 17 - Evaluate on 511 samples: Average loss: 0.4955, Accuracy: 80.63%

Client 3 round 18 (before train) - Evaluate on 511 samples: Average loss: 0.4955, Accuracy: 80.63%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.550494				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.492893				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.568991				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.500878				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.560425				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.565962				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.512259				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.393658				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.451831				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.337314				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.433619				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.538098				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.579367				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.431569				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.600690				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.499639				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.313303				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.573532				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.607005				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.585286				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.470593				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.500810				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.576573				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.528971				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.552355				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.636544				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.453043				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.357229				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.710799				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.556103				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.505286				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.368603				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.430837				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.663406				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.481214				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.624988				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.444037				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.515808				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.558043				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.489064				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.490332				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.480036				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.391258				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.659504				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.547233				Client 3 should_send_params: False 


 Client 3 round 18 returning params_prime of size 169  

Client 3 round 18 - Evaluate on 511 samples: Average loss: 0.4933, Accuracy: 81.60%

Client 3 round 19 (before train) - Evaluate on 511 samples: Average loss: 0.4933, Accuracy: 81.60%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.530958				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.498513				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.590694				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.521020				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.463779				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.425513				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.469239				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.382895				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.392388				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.518017				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.504040				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.572290				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.558392				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.378660				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.718775				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.523222				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.377533				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.505490				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.647515				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.706005				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.416649				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.426955				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.550551				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.578045				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.491503				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.420583				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.491482				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.544399				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.494636				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.615979				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.754060				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.513504				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.613863				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.485968				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.424407				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.504409				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.509081				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.573270				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.383005				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.500219				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.488386				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.561201				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.639266				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.498786				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.424744				Client 3 should_send_params: True 


 Client 3 round 19 returning params_prime of size 4800816  

Client 3 round 19 - Evaluate on 511 samples: Average loss: 0.4875, Accuracy: 81.60%

Client 3 round 20 (before train) - Evaluate on 511 samples: Average loss: 0.4875, Accuracy: 81.60%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.420475				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.446248				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.598572				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.614167				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.555162				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.443428				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.336578				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.597429				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.362299				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.562421				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.389335				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.402650				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.389069				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.503676				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.460494				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.545331				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.449128				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.649693				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.322828				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.383741				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.518195				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.499280				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.463337				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.514078				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.342896				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.543584				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.766812				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.384952				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.544268				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.430876				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.619683				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.695157				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.479689				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.430442				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.355399				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.418642				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.525386				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.325088				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.604886				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.484516				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.520787				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.348806				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.560843				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.415088				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.491345				DEBUG flower 2022-04-18 00:11:42,669 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-04-18 00:11:42,669 | app.py:72 | Disconnect and shut down
Client 3 should_send_params: True 


 Client 3 round 20 returning params_prime of size 4800816  

Client 3 round 20 - Evaluate on 511 samples: Average loss: 0.4840, Accuracy: 82.00%

