DEBUG flower 2022-04-17 22:38:52,395 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2022-04-17 22:38:52,396 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2022-04-17 22:38:52,396 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2022-04-17 22:38:52,396 | app.py:61 | Opened (insecure) gRPC connection
Client CID: 4
[28016 28321 47294 53184]
[1344 3713 4197 4708]
Client 4 round 1 (before train) - Evaluate on 5292 samples: Average loss: 2.2995, Accuracy: 10.00%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.317813				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.285022				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.288866				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.284338				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.275820				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.252736				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.265115				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.240927				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.241570				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.233595				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.224312				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.191809				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.170372				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.167103				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.177944				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.172859				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.140023				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.109516				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.098431				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.123612				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.048749				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.065262				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.104859				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.012233				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.001524				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.984631				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.983126				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.927625				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.947827				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.990448				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.858663				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.841025				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.870944				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.872987				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.854246				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.776017				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.742828				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.718652				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.798536				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.659356				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.773867				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.547194				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.597158				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.459657				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.536146				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.666966				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.471827				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.534114				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.521374				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.496970				Client 4 should_send_params: True 


 Client 4 round 1 returning params_prime of size 4800816  

Client 4 round 1 - Evaluate on 5292 samples: Average loss: 0.8189, Accuracy: 73.39%

Client 4 round 2 (before train) - Evaluate on 5292 samples: Average loss: 0.8189, Accuracy: 73.39%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.909354				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.085737				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.975352				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.890722				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.791885				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.924184				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.917500				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.923093				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.810140				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.998137				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.913833				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.759725				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.949288				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.899992				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.878976				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.805890				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.864185				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.804621				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.803642				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.675688				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.986259				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.731596				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.652052				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.996624				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.941254				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.815438				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.904353				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.725805				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.876066				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.801284				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.784308				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.949080				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.642440				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.691359				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.793782				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.685151				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.708483				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.813427				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.844926				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.759424				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.788017				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.084866				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.779650				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.635491				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.766600				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.839215				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.793088				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.819219				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.713879				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.988915				Client 4 should_send_params: False 


 Client 4 round 2 returning params_prime of size 169  

Client 4 round 2 - Evaluate on 5292 samples: Average loss: 0.7062, Accuracy: 74.83%

Client 4 round 3 (before train) - Evaluate on 5292 samples: Average loss: 0.7062, Accuracy: 74.83%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.066997				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.998258				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.604682				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.852629				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.746121				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.688156				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.763719				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.811036				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.823509				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.789579				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.732705				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.620542				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.808396				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.626818				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.052163				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.760846				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.768645				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.564274				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.726865				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.855322				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.853864				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.713547				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.602197				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.836791				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.805136				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.677585				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.757488				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.751505				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.914782				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.675794				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.765943				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.885790				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.758788				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.821182				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.844184				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.808422				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.779036				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.752072				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.739100				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.554154				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.806437				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.770878				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.875297				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.839783				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.882760				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.744627				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.804306				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.727817				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.804227				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.665025				Client 4 should_send_params: False 


 Client 4 round 3 returning params_prime of size 169  

Client 4 round 3 - Evaluate on 5292 samples: Average loss: 0.6580, Accuracy: 76.06%

Client 4 round 4 (before train) - Evaluate on 5292 samples: Average loss: 0.6580, Accuracy: 76.06%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.693330				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.045386				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.839517				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.548544				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.629114				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.775463				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.928184				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.755380				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.776549				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.928846				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.574273				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.627531				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.740969				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.863039				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.750043				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.554755				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.624078				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.758662				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.693683				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.739477				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.795413				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.658746				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.725644				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.696700				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.578482				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.675263				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.490471				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.744738				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.843874				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.832532				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.530472				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.726719				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.688795				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.715912				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.599590				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.800923				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.508366				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.595982				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.938438				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.824977				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.565059				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.512464				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.518195				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.753467				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.766308				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.591660				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.921670				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.853927				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.798593				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.596757				Client 4 should_send_params: False 


 Client 4 round 4 returning params_prime of size 169  

Client 4 round 4 - Evaluate on 5292 samples: Average loss: 0.6250, Accuracy: 77.17%

Client 4 round 5 (before train) - Evaluate on 5292 samples: Average loss: 0.6250, Accuracy: 77.17%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.797663				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.740116				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.836321				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.612118				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.593495				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.791004				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.704141				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.815405				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.632159				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.963950				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.719378				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.560376				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.529102				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.776526				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.574360				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.521270				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.631926				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.756274				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.510397				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.600514				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.803477				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.433726				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.710339				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.771813				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.577344				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.642054				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.516524				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.678958				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.813990				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.649588				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.893385				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.808466				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.712048				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.826578				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.611590				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.794862				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.583305				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.793471				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.728117				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.833186				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.838238				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.530761				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.685781				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.671005				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.635648				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.768405				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.609431				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.735887				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.798938				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.915402				Client 4 should_send_params: False 


 Client 4 round 5 returning params_prime of size 169  

Client 4 round 5 - Evaluate on 5292 samples: Average loss: 0.6042, Accuracy: 77.53%

Client 4 round 6 (before train) - Evaluate on 5292 samples: Average loss: 0.6042, Accuracy: 77.53%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.580206				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.600018				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.517117				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.546829				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.587052				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.716289				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.856168				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.728503				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.830468				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.578946				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.840688				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.648217				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.459400				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.459996				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.558438				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.638480				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.734473				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.900498				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.543362				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.635839				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.618054				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.880879				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.771774				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.617021				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.619897				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.634467				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.600040				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.726133				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.607264				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.645661				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.836590				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.768933				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.658187				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.623036				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.737402				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.662248				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.661145				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.649250				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.742493				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.546365				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.575166				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.571558				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.514781				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.684892				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.648462				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.607844				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.517783				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.482455				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.632325				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.597553				Client 4 should_send_params: False 


 Client 4 round 6 returning params_prime of size 169  

Client 4 round 6 - Evaluate on 5292 samples: Average loss: 0.5830, Accuracy: 78.51%

Client 4 round 7 (before train) - Evaluate on 5292 samples: Average loss: 0.5830, Accuracy: 78.51%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.478566				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.595349				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.799549				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.481189				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.599263				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.674108				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.556105				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.650578				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.609243				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.583082				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.641370				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.484242				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.766055				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.587451				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.637261				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.789258				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.691440				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.522344				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.497455				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.485865				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.522743				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.861480				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.546290				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.585006				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.709109				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.557628				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.691930				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.499123				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.744198				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.576572				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.591746				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.629549				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.643246				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.588887				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.425340				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.842021				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.571055				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.381935				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.484481				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.704307				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.679301				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.642272				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.528419				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.617380				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.629025				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.734824				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.687900				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.581537				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.799860				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.403547				Client 4 should_send_params: False 


 Client 4 round 7 returning params_prime of size 169  

Client 4 round 7 - Evaluate on 5292 samples: Average loss: 0.5667, Accuracy: 78.68%

Client 4 round 8 (before train) - Evaluate on 5292 samples: Average loss: 0.5667, Accuracy: 78.68%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.425537				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.836588				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.701884				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.503612				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.760967				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.800886				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.692081				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.565751				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.461409				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.562423				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.868707				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.539465				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.729278				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.764848				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.567130				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.519492				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.496584				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.636375				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.536316				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.682683				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.828956				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.613463				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.589472				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.603224				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.664172				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.412670				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.638883				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.804766				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.856952				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.597842				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.700116				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.539472				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.481403				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.817233				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.687174				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.700240				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.687936				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.525938				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.485564				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.551383				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.519198				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.708732				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.519691				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.509107				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.752183				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.651943				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.873651				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.496643				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.614885				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.604032				Client 4 should_send_params: True 


 Client 4 round 8 returning params_prime of size 4800816  

Client 4 round 8 - Evaluate on 5292 samples: Average loss: 0.5528, Accuracy: 79.71%

Client 4 round 9 (before train) - Evaluate on 5292 samples: Average loss: 0.5528, Accuracy: 79.71%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.613396				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.694544				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.481113				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.595086				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.665631				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.555996				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.654635				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.558029				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.643360				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.587896				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.730516				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.576867				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.663672				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.515243				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.582958				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.602811				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.715827				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.621583				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.473101				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.596036				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.557185				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.339507				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.615416				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.636360				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.626052				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.550367				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.580636				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.520481				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.546906				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.664199				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.722274				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.578415				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.548825				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.554462				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.676961				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.537335				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.512548				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.572081				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.816287				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.636563				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.524587				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.603339				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.591045				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.560276				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.507238				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.781888				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.494541				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.744905				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.502383				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.347020				Client 4 should_send_params: False 


 Client 4 round 9 returning params_prime of size 169  

Client 4 round 9 - Evaluate on 5292 samples: Average loss: 0.5392, Accuracy: 80.29%

Client 4 round 10 (before train) - Evaluate on 5292 samples: Average loss: 0.5392, Accuracy: 80.29%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.607245				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.440451				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.762770				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.563787				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.441538				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.623055				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.529238				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.688063				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.509979				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.485499				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.659604				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.617311				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.627670				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.660788				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.504727				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.652356				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.580087				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.614720				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.625149				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.666430				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.526850				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.679992				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.490660				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.591917				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.520733				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.449644				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.650221				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.601611				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.750917				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.722763				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.794911				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.415046				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.556780				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.651021				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.562210				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.472067				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.688035				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.566627				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.722687				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.697581				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.576635				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.567164				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.426364				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.724699				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.588685				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.678368				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.571174				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.556614				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.616753				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.672412				Client 4 should_send_params: False 


 Client 4 round 10 returning params_prime of size 169  

Client 4 round 10 - Evaluate on 5292 samples: Average loss: 0.5282, Accuracy: 80.76%

Client 4 round 11 (before train) - Evaluate on 5292 samples: Average loss: 0.5282, Accuracy: 80.76%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.621024				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.511039				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.622982				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.510619				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.561102				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.515523				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.476342				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.636999				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.609189				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.570972				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.619467				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.414108				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.597180				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.790606				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.387726				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.656976				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.566651				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.724987				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.598781				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.652501				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.470374				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.543795				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.589149				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.423989				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.517031				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.349475				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.521018				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.526325				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.522586				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.421987				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.586260				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.502291				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.637038				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.342706				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.466644				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.456092				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.545189				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.645755				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.537887				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.468013				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.551258				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.497308				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.562831				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.663270				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.568839				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.698168				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.494944				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.537080				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.489766				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.541655				Client 4 should_send_params: True 


 Client 4 round 11 returning params_prime of size 4800816  

Client 4 round 11 - Evaluate on 5292 samples: Average loss: 0.5220, Accuracy: 80.88%

Client 4 round 12 (before train) - Evaluate on 5292 samples: Average loss: 0.5220, Accuracy: 80.88%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.397337				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.882538				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.533965				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.627015				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.557573				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.417345				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.694435				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.448660				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.580560				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.426191				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.566418				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.499177				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.643244				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.659558				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.636269				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.529583				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.485728				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.500570				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.559640				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.719838				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.782806				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.590199				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.578549				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.506576				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.649696				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.603937				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.479282				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.389213				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.493863				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.508408				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.435096				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.440948				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.580411				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.682853				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.500614				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.579285				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.386896				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.451297				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.493586				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.593231				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.606768				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.617918				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.686669				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.605546				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.678398				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.589721				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.570115				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.611094				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.570998				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.369309				Client 4 should_send_params: True 


 Client 4 round 12 returning params_prime of size 4800816  

Client 4 round 12 - Evaluate on 5292 samples: Average loss: 0.5135, Accuracy: 81.50%

Client 4 round 13 (before train) - Evaluate on 5292 samples: Average loss: 0.5135, Accuracy: 81.50%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.632922				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.448642				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.604045				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.648084				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.637627				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.458472				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.734595				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.457005				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.663718				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.467134				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.727364				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.504398				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.506821				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.469647				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.733014				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.616351				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.616378				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.424974				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.737534				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.522955				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.408797				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.616322				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.620329				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.491381				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.344156				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.514629				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.707993				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.573065				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.605616				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.387204				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.465984				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.589786				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.454309				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.372061				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.511347				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.638603				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.467735				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.532064				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.439150				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.697362				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.633053				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.423194				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.563998				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.572681				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.496713				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.463914				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.455039				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.311150				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.575304				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.318857				Client 4 should_send_params: False 


 Client 4 round 13 returning params_prime of size 169  

Client 4 round 13 - Evaluate on 5292 samples: Average loss: 0.5057, Accuracy: 81.56%

Client 4 round 14 (before train) - Evaluate on 5292 samples: Average loss: 0.5057, Accuracy: 81.56%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.601215				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.561608				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.785285				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.418705				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.744057				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.526084				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.451342				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.580763				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.546372				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.633686				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.594136				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.483389				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.429453				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.628781				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.611423				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.510962				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.584745				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.363605				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.552113				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.520377				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.439872				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.725333				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.483371				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.358813				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.465949				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.585382				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.450431				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.479501				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.422256				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.584077				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.667414				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.613325				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.602472				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.580480				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.529505				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.396718				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.517746				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.565435				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.354058				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.600346				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.487686				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.470013				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.455455				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.454601				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.347732				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.611978				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.495996				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.318395				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.492765				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.601158				Client 4 should_send_params: True 


 Client 4 round 14 returning params_prime of size 4800816  

Client 4 round 14 - Evaluate on 5292 samples: Average loss: 0.4979, Accuracy: 81.90%

Client 4 round 15 (before train) - Evaluate on 5292 samples: Average loss: 0.4979, Accuracy: 81.90%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.394878				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.439219				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.353499				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.370287				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.543354				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.652821				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.529079				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.348443				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.851381				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.525208				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.564481				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.683042				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.457989				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.376858				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.769705				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.532424				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.481448				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.711199				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.344273				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.477310				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.756591				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.447212				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.474225				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.466602				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.593063				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.379576				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.354594				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.619684				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.340759				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.476685				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.568244				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.676005				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.444192				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.564097				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.460678				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.428100				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.626351				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.551749				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.538270				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.539447				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.513379				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.531057				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.527358				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.483183				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.505677				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.367543				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.866655				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.444253				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.602692				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.458122				Client 4 should_send_params: True 


 Client 4 round 15 returning params_prime of size 4800816  

Client 4 round 15 - Evaluate on 5292 samples: Average loss: 0.4898, Accuracy: 82.33%

Client 4 round 16 (before train) - Evaluate on 5292 samples: Average loss: 0.4898, Accuracy: 82.33%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.453930				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.428320				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.355310				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.524621				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.582570				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.690829				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.469684				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.475833				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.516353				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.525644				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.631910				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.529805				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.555538				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.585790				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.523917				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.413738				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.484115				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.507390				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.271048				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.546679				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.611258				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.535564				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.367899				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.465477				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.354257				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.649333				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.398589				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.485083				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.500800				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.414281				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.577925				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.568897				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.384679				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.374763				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.477995				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.674688				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.452989				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.395345				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.450817				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.477630				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.641282				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.572879				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.508322				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.511958				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.451802				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.508392				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.396526				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.626483				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.322522				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.409130				Client 4 should_send_params: True 


 Client 4 round 16 returning params_prime of size 4800816  

Client 4 round 16 - Evaluate on 5292 samples: Average loss: 0.4840, Accuracy: 82.45%

Client 4 round 17 (before train) - Evaluate on 5292 samples: Average loss: 0.4840, Accuracy: 82.45%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.410006				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.418951				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.563603				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.363838				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.458656				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.500259				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.365450				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.485103				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.350232				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.514647				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.481489				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.342489				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.426141				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.545006				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.627918				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.554939				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.371089				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.776534				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.877769				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.610060				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.558753				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.507800				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.529061				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.452805				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.560145				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.602827				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.423919				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.607148				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.452816				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.585966				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.472406				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.406108				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.578636				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.488728				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.349176				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.406309				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.472279				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.622769				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.597932				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.649170				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.415558				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.496926				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.401955				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.628638				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.444119				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.447172				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.380676				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.582378				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.601318				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.436100				Client 4 should_send_params: False 


 Client 4 round 17 returning params_prime of size 169  

Client 4 round 17 - Evaluate on 5292 samples: Average loss: 0.4822, Accuracy: 82.69%

Client 4 round 18 (before train) - Evaluate on 5292 samples: Average loss: 0.4822, Accuracy: 82.69%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.487263				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.352081				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.474002				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.250917				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.695621				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.497604				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.386416				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.334246				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.473973				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.452230				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.424877				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.508761				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.565415				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.544402				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.523693				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.488221				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.293651				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.388160				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.675990				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.554631				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.550203				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.486028				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.448279				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.470789				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.701299				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.462237				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.469464				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.414622				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.465379				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.499197				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.668027				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.411194				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.658065				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.540831				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.415606				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.549953				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.615092				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.753655				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.426447				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.489854				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.400891				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.364549				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.429921				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.522826				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.507617				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.553723				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.484467				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.663387				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.449009				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.542445				Client 4 should_send_params: True 


 Client 4 round 18 returning params_prime of size 4800816  

Client 4 round 18 - Evaluate on 5292 samples: Average loss: 0.4747, Accuracy: 83.11%

Client 4 round 19 (before train) - Evaluate on 5292 samples: Average loss: 0.4747, Accuracy: 83.11%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.518189				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.343552				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.481912				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.604736				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.484360				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.460615				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.377781				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.605182				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.465864				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.437790				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.433408				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.464247				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.484771				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.275992				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.343914				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.638362				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.575623				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.411807				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.548397				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.330804				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.429159				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.511501				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.734977				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.489071				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.668535				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.498228				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.430944				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.645283				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.485334				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.381893				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.593083				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.433404				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.653177				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.470814				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.529465				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.394835				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.403719				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.503671				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.424795				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.513829				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.440481				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.484956				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.519104				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.386393				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.331013				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.400467				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.402911				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.520990				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.598757				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.393566				Client 4 should_send_params: False 


 Client 4 round 19 returning params_prime of size 169  

Client 4 round 19 - Evaluate on 5292 samples: Average loss: 0.4688, Accuracy: 83.47%

Client 4 round 20 (before train) - Evaluate on 5292 samples: Average loss: 0.4688, Accuracy: 83.47%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.614066				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.469897				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.523047				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.458913				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.531882				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.545671				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.329751				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.387931				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.467782				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.554657				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.480457				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.413503				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.431825				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.495057				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.348530				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.421591				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.483175				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.496985				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.439792				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.522233				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.396616				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.452623				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.346784				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.575319				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.618272				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.524089				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.421435				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.603185				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.316927				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.489556				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.355076				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.536809				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.394055				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.374924				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.515655				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.344712				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.433574				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.527986				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.392399				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.386655				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.655773				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.386702				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.486101				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.450531				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.429587				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.295871				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.317364				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.497851				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.304108				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.512927				DEBUG flower 2022-04-18 00:11:42,661 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-04-18 00:11:42,661 | app.py:72 | Disconnect and shut down
Client 4 should_send_params: False 


 Client 4 round 20 returning params_prime of size 169  

Client 4 round 20 - Evaluate on 5292 samples: Average loss: 0.4657, Accuracy: 83.26%

