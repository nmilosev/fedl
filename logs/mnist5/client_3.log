DEBUG flower 2022-04-17 20:15:13,509 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2022-04-17 20:15:13,510 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2022-04-17 20:15:13,510 | connection.py:36 | ChannelConnectivity.READY
Client CID: 3
[28016 28321 47294 53184]
[1344 3713 4197 4708]
Client 3 round 1 (before train) - Evaluate on 511 samples: Average loss: 2.2954, Accuracy: 14.68%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.338938				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.303542				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.316821				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.307081				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.327290				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.314375				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.303796				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.303308				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.317286				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.286417				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.299562				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.314192				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.273928				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.302693				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.291716				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.311093				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.309163				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.294819				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.293688				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.282508				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.304985				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.301524				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.316123				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.315491				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.290767				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.312789				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.314819				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.319305				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.299242				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.286678				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.286625				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.307920				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.321625				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.296464				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.303755				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.285232				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.290211				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.311791				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.300566				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.299378				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.297563				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.297674				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.280307				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.304622				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.288499				Client 3 should_send_params: True 


 Client 3 round 1 returning params_prime of size 4800816  

Client 3 round 1 - Evaluate on 511 samples: Average loss: 2.2357, Accuracy: 38.16%

Client 3 round 2 (before train) - Evaluate on 511 samples: Average loss: 2.2357, Accuracy: 38.16%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.253006				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.239573				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.242570				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.253046				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.262064				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.243390				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.236087				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.259856				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.260982				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.226885				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.236140				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.266606				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.235749				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.248173				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.215580				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.252725				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.229594				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.237660				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.232925				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.233573				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.221377				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.249617				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.213408				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.237620				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.248055				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.270293				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.248713				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.241966				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.230298				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.286625				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.239754				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.262409				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.239422				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.239526				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.246197				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.227315				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.246885				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.247292				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.225577				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.256304				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.224171				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.237427				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.248163				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.221566				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.231801				Client 3 should_send_params: False 


 Client 3 round 2 returning params_prime of size 169  

Client 3 round 2 - Evaluate on 511 samples: Average loss: 2.2165, Accuracy: 44.81%

Client 3 round 3 (before train) - Evaluate on 511 samples: Average loss: 2.2165, Accuracy: 44.81%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.232901				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.222436				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.212085				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.233580				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.181776				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.255515				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.238114				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.226199				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.212826				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.224138				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.214831				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.225617				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.221061				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.189422				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.249195				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.250147				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.242546				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.181437				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.235459				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.224948				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.219320				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.175071				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.215389				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.230474				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.234147				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.232368				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.202822				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.228573				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.197900				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.214458				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.213679				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.231597				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.204500				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.209012				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.250759				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.228542				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.232338				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.271373				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.224205				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.235977				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.199342				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.226668				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.218684				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.216434				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.208730				Client 3 should_send_params: True 


 Client 3 round 3 returning params_prime of size 4800816  

Client 3 round 3 - Evaluate on 511 samples: Average loss: 2.1959, Accuracy: 50.49%

Client 3 round 4 (before train) - Evaluate on 511 samples: Average loss: 2.1959, Accuracy: 50.49%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.231613				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.203598				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.208900				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.223526				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.224374				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.219757				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.207134				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.204742				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.178835				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.185514				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.193128				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.200249				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.178061				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.175832				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.187493				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.217939				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.195049				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.194066				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.177234				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.206290				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.211945				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.211741				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.215764				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.219535				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.204968				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.193656				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.175191				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.194279				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.207063				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.192844				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.176879				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.185905				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.203758				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.226406				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.208817				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.201211				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.193343				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.184700				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.206144				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.217502				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.214400				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.204575				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.194615				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.205232				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.184811				Client 3 should_send_params: True 


 Client 3 round 4 returning params_prime of size 4800816  

Client 3 round 4 - Evaluate on 511 samples: Average loss: 2.1735, Accuracy: 53.62%

Client 3 round 5 (before train) - Evaluate on 511 samples: Average loss: 2.1735, Accuracy: 53.62%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.172087				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.175529				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.201691				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.171667				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.204492				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.190898				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.189007				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.195876				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.171510				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.135444				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.179865				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.190525				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.163284				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.201869				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.176439				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.206178				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.145699				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.168514				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.202338				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.155860				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.190290				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.159749				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.133484				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.173581				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.172900				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.160529				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.204684				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.192537				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.164438				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.204579				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.185017				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.186582				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.203664				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.144493				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.174271				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.202797				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.169326				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.158741				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.161187				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.143687				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.176470				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.208717				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.185637				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.149611				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.168910				Client 3 should_send_params: True 


 Client 3 round 5 returning params_prime of size 4800816  

Client 3 round 5 - Evaluate on 511 samples: Average loss: 2.1494, Accuracy: 56.36%

Client 3 round 6 (before train) - Evaluate on 511 samples: Average loss: 2.1494, Accuracy: 56.36%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.181040				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.154565				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.158316				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.174870				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.146578				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.154310				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.146713				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.173522				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.173121				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.175113				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.141147				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.172467				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.166061				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.159615				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.180292				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.111998				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.134907				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.166395				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.152687				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.150617				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.161857				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.169449				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.171047				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.130961				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.144281				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.137597				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.151973				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.165523				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.164961				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.181843				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.121633				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.190402				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.143070				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.152170				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.135009				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.172562				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.124347				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.185853				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.137721				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.165731				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.139823				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.117308				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.136011				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.155321				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.152914				Client 3 should_send_params: True 


 Client 3 round 6 returning params_prime of size 4800816  

Client 3 round 6 - Evaluate on 511 samples: Average loss: 2.1237, Accuracy: 60.47%

Client 3 round 7 (before train) - Evaluate on 511 samples: Average loss: 2.1237, Accuracy: 60.47%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.147632				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.142621				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.137309				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.134655				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.092804				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.115698				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.122929				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.110295				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.127902				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.118086				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.168693				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.155772				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.154075				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.152123				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.155202				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.109305				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.130206				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.157947				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.120814				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.154314				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.134176				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.112931				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.100936				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.123980				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.072576				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.113282				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.092786				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.148287				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.143701				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.168906				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.107263				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.147414				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.116606				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.121398				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.105299				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.074699				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.072745				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.142894				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.130613				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.115411				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.101033				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.130430				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.078152				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.130359				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.113150				Client 3 should_send_params: True 


 Client 3 round 7 returning params_prime of size 4800816  

Client 3 round 7 - Evaluate on 511 samples: Average loss: 2.0966, Accuracy: 61.06%

Client 3 round 8 (before train) - Evaluate on 511 samples: Average loss: 2.0966, Accuracy: 61.06%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.133512				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.125898				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.077181				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.142690				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.129662				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.128309				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.144194				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.120470				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.104404				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.138896				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.124407				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.091419				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.098740				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.074624				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.172385				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.083221				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.105111				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.123673				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.107304				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.129800				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.050617				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.103784				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.076024				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.109950				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.073175				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.090316				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.119452				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.055443				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.079600				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.072995				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.148431				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.099529				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.058019				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.110236				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.071114				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.070967				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.085396				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.103646				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.085385				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.069179				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.086806				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.085505				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.130260				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.111217				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.083383				Client 3 should_send_params: True 


 Client 3 round 8 returning params_prime of size 4800816  

Client 3 round 8 - Evaluate on 511 samples: Average loss: 2.0680, Accuracy: 62.43%

Client 3 round 9 (before train) - Evaluate on 511 samples: Average loss: 2.0680, Accuracy: 62.43%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.105559				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.065121				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.055009				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.095095				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.071198				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.126503				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.078237				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.113386				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.071252				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.088471				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.092010				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.077249				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.069197				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.085349				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.059323				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.058910				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.013993				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.073080				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.029511				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.088378				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.072255				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.107102				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.119884				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.080194				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.060506				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.096195				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.068709				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.075517				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.055468				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.050534				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.024710				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.077816				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.062511				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.066908				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.031867				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.132120				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.053314				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.066090				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.102743				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.068201				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.068789				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.076856				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.992610				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.046762				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.058230				Client 3 should_send_params: True 


 Client 3 round 9 returning params_prime of size 4800816  

Client 3 round 9 - Evaluate on 511 samples: Average loss: 2.0384, Accuracy: 62.04%

Client 3 round 10 (before train) - Evaluate on 511 samples: Average loss: 2.0384, Accuracy: 62.04%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.083574				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.071389				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.099596				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.087102				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.073124				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.087304				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.091388				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.049576				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.096489				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.043447				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.036810				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.022261				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.056332				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.050736				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.007970				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.068172				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.061646				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.072634				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.020565				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.022120				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.053711				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.044589				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.990195				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 2.062153				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.002384				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.017693				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.052318				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 2.021469				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.004475				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.080843				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.040892				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.091778				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 2.031574				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 2.005819				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 2.033298				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.036131				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.006621				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.988714				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.038346				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.000099				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.023880				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.062768				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.047786				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.997912				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.040804				Client 3 should_send_params: True 


 Client 3 round 10 returning params_prime of size 4800816  

Client 3 round 10 - Evaluate on 511 samples: Average loss: 2.0076, Accuracy: 62.62%

Client 3 round 11 (before train) - Evaluate on 511 samples: Average loss: 2.0076, Accuracy: 62.62%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.017535				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.003769				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.038584				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 1.987409				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.016260				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 1.954017				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.035995				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.047231				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.037451				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.976801				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 1.972415				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.074536				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.048471				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.017452				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.038659				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.030186				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.005745				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.058869				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.058689				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.038146				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.015643				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.997619				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.914016				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.979254				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 2.000400				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.012502				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.049941				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.988014				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.048645				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.020960				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 2.031006				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 2.011592				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.925897				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.993901				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.944419				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.991038				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 2.054960				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.041221				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.045678				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 2.053795				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.068225				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 2.021041				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.975563				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.039876				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.971704				Client 3 should_send_params: True 


 Client 3 round 11 returning params_prime of size 4800816  

Client 3 round 11 - Evaluate on 511 samples: Average loss: 1.9754, Accuracy: 62.62%

Client 3 round 12 (before train) - Evaluate on 511 samples: Average loss: 1.9754, Accuracy: 62.62%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.036927				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 1.982734				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.960080				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.020367				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.971933				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.001347				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 1.989678				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.064022				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.001367				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.963048				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.008224				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 1.938897				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.043327				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 1.998795				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.016174				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.020489				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 1.974054				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 1.982957				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.978887				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.990945				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.985675				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.967244				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.975592				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.906847				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.931968				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 2.004138				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.965966				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.963873				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 2.055353				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.010418				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.962728				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.971424				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.976511				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.907221				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.911223				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 2.000519				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.901915				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 2.001084				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.951438				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.947073				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.911594				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.982206				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 2.015722				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 2.005714				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.996799				Client 3 should_send_params: True 


 Client 3 round 12 returning params_prime of size 4800816  

Client 3 round 12 - Evaluate on 511 samples: Average loss: 1.9418, Accuracy: 63.41%

Client 3 round 13 (before train) - Evaluate on 511 samples: Average loss: 1.9418, Accuracy: 63.41%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 1.977386				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 1.890247				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.967472				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 1.986557				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.935554				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 1.933316				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 1.959685				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 1.919791				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.011103				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.937247				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 1.958590				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 1.944876				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 1.992085				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 1.930159				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 1.946578				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 1.857585				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 1.962354				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 1.984452				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.959642				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.994222				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.924555				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.904323				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.910433				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.907125				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.990243				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.877892				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.976519				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.873791				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.927652				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 2.038776				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.948935				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.998478				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.953093				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.945349				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.922315				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.965210				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.978917				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.913622				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 2.019034				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.951904				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 2.000602				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.919493				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.884841				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.911605				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.877852				Client 3 should_send_params: True 


 Client 3 round 13 returning params_prime of size 4800816  

Client 3 round 13 - Evaluate on 511 samples: Average loss: 1.9075, Accuracy: 64.19%

Client 3 round 14 (before train) - Evaluate on 511 samples: Average loss: 1.9075, Accuracy: 64.19%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 1.962545				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 1.964032				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.988178				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 1.937288				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.894434				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 1.894957				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 1.906491				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 1.977509				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 1.962804				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.861531				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 1.956835				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 1.899052				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 1.895691				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 1.928398				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 1.873765				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 1.987763				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 1.935718				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 1.957214				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.936458				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.946585				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.886132				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.928297				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.915216				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.942663				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.888695				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.903187				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.907214				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.910665				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.946354				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.829147				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.934480				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.886019				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.982506				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.875066				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.964597				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.947424				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.969429				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.943813				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.899224				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.890399				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.874195				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.827666				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.963228				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.814945				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 2.018428				Client 3 should_send_params: True 


 Client 3 round 14 returning params_prime of size 4800816  

Client 3 round 14 - Evaluate on 511 samples: Average loss: 1.8720, Accuracy: 64.97%

Client 3 round 15 (before train) - Evaluate on 511 samples: Average loss: 1.8720, Accuracy: 64.97%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 1.882404				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 1.936867				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.885899				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 1.816827				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.849907				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 1.880727				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 1.872817				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 1.978161				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 1.929949				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.922950				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 1.856324				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 1.860934				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 1.916490				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 1.901745				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 1.872311				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 1.862947				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 1.862792				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 1.863926				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.918491				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.796227				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.908107				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.904155				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.815661				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.893294				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.901876				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.871055				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.896299				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.937386				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.831166				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.931238				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.820596				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.835605				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.836912				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.872708				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.864245				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.823098				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.900260				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.880802				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.931742				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.827467				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.824910				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.898193				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.836960				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.796457				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.780152				Client 3 should_send_params: False 


 Client 3 round 15 returning params_prime of size 169  

Client 3 round 15 - Evaluate on 511 samples: Average loss: 1.8347, Accuracy: 65.95%

Client 3 round 16 (before train) - Evaluate on 511 samples: Average loss: 1.8347, Accuracy: 65.95%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 1.888251				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 1.896757				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.878236				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 1.866300				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.883613				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 1.817150				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 1.799273				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 1.874380				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 1.885927				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.903532				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 1.790250				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 1.849868				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 1.848877				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 1.861094				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 1.785598				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 1.831074				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 1.910921				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 1.835623				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.833534				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.886351				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.860626				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.862700				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.819614				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.827531				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.807362				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.856478				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.786644				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.893880				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.763234				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.845753				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.790208				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.841472				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.882288				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.822686				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.838720				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.841641				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.842162				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.829761				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.837427				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.821889				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.873571				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.847497				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.831491				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.723596				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.788091				Client 3 should_send_params: True 


 Client 3 round 16 returning params_prime of size 4800816  

Client 3 round 16 - Evaluate on 511 samples: Average loss: 1.7971, Accuracy: 66.14%

Client 3 round 17 (before train) - Evaluate on 511 samples: Average loss: 1.7971, Accuracy: 66.14%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 1.744862				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 1.880623				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.841631				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 1.850172				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.862869				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 1.780059				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 1.761790				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 1.855375				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 1.838115				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.828350				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 1.754225				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 1.856357				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 1.826785				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 1.849231				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 1.904527				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 1.824123				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 1.873803				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 1.836446				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.829096				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.818037				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.833129				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.815312				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.749842				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.889518				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.810799				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.891587				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.779555				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.802821				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.848935				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.803444				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.743742				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.852759				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.740396				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.797321				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.817815				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.850218				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.752662				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.863590				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.767249				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.773583				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.758484				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.763292				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.686651				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.860673				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.832149				Client 3 should_send_params: False 


 Client 3 round 17 returning params_prime of size 169  

Client 3 round 17 - Evaluate on 511 samples: Average loss: 1.7589, Accuracy: 66.73%

Client 3 round 18 (before train) - Evaluate on 511 samples: Average loss: 1.7589, Accuracy: 66.73%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 1.859736				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 1.822632				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.838495				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 1.731848				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.728689				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 1.875906				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 1.668529				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 1.842224				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 1.818608				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.784971				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 1.731548				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 1.754790				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 1.852306				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 1.802629				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 1.827595				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 1.766823				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 1.762794				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 1.760424				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.873987				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.803760				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.749439				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.758274				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.780082				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.742645				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.782279				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.685323				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.775797				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.817437				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.847192				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.824789				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.868625				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.801739				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.749697				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.718328				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.708558				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.750150				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.793573				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.700867				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.820731				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.681189				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.740518				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.671022				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.683126				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.770110				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.704325				Client 3 should_send_params: True 


 Client 3 round 18 returning params_prime of size 4800816  

Client 3 round 18 - Evaluate on 511 samples: Average loss: 1.7197, Accuracy: 67.12%

Client 3 round 19 (before train) - Evaluate on 511 samples: Average loss: 1.7197, Accuracy: 67.12%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 1.714096				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 1.794040				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.730673				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 1.797305				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.747721				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 1.776390				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 1.760856				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 1.716119				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 1.763421				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.747342				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 1.765260				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 1.827963				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 1.678981				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 1.765980				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 1.771670				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 1.809993				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 1.749561				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 1.698357				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.755068				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.667971				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.716716				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.851021				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.707462				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.837611				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.803085				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.740398				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.723775				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.729558				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.813697				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.787254				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.742213				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.677620				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.732123				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.781981				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.691804				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.831803				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.721399				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.664413				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.743061				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.837024				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.712791				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.742293				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.656972				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.726949				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.730276				Client 3 should_send_params: True 


 Client 3 round 19 returning params_prime of size 4800816  

Client 3 round 19 - Evaluate on 511 samples: Average loss: 1.6803, Accuracy: 68.69%

Client 3 round 20 (before train) - Evaluate on 511 samples: Average loss: 1.6803, Accuracy: 68.69%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 1.721501				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 1.621944				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.760078				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 1.735721				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 1.774707				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 1.738496				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 1.790208				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 1.763424				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 1.732310				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 1.720980				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 1.724636				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 1.688823				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 1.737898				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 1.634372				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 1.652704				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 1.750650				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 1.805600				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 1.678275				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.752869				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 1.658610				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 1.617965				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 1.692742				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 1.792797				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.686218				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.710730				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.710923				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 1.668198				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.716627				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.746354				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.767254				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.781119				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.585236				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.712543				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.707093				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.685592				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.596626				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.677492				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.712862				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.669309				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.640141				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.586428				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.622010				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.713884				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.653325				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.722305				DEBUG flower 2022-04-17 21:47:12,161 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-04-17 21:47:12,161 | app.py:72 | Disconnect and shut down
Client 3 should_send_params: True 


 Client 3 round 20 returning params_prime of size 4800816  

Client 3 round 20 - Evaluate on 511 samples: Average loss: 1.6398, Accuracy: 69.28%

