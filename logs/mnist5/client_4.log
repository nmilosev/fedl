DEBUG flower 2022-04-17 20:15:13,468 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2022-04-17 20:15:13,469 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2022-04-17 20:15:13,469 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2022-04-17 20:15:13,469 | connection.py:36 | ChannelConnectivity.READY
Client CID: 4
[28016 28321 47294 53184]
[1344 3713 4197 4708]
Client 4 round 1 (before train) - Evaluate on 5292 samples: Average loss: 2.3057, Accuracy: 10.73%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.316612				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.335424				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.296068				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.316950				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.320021				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.298432				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.307135				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.315829				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.286871				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.305796				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.300483				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.314869				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.300243				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.300611				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.305481				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.333839				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.309104				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.300395				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.295665				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.298496				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.304318				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.280709				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.297807				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.295675				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.284475				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 2.323339				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.287187				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.287137				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 2.292963				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 2.288746				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.302636				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 2.279463				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.270153				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 2.297482				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 2.316191				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 2.271478				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 2.292698				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 2.271628				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.285528				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.282042				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 2.298497				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.292604				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 2.285801				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 2.294444				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 2.270678				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 2.273582				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.296031				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.307205				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 2.294166				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 2.309802				Client 4 should_send_params: True 


 Client 4 round 1 returning params_prime of size 4800816  

Client 4 round 1 - Evaluate on 5292 samples: Average loss: 2.2394, Accuracy: 33.37%

Client 4 round 2 (before train) - Evaluate on 5292 samples: Average loss: 2.2394, Accuracy: 33.37%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.250362				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.253777				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.216943				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.238365				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.243880				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.244182				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.220161				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.246629				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.249608				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.254754				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.218664				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.245595				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.259171				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.257005				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.248609				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.276817				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.254577				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.239739				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.223008				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.256762				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.246398				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.242579				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.243366				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.234038				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.231931				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 2.229980				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.218121				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.239465				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 2.252960				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 2.229488				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.238867				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 2.240366				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.251468				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 2.249394				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 2.242062				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 2.242998				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 2.237898				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 2.230236				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.235939				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.236393				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 2.253040				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.245496				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 2.248691				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 2.227118				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 2.221230				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 2.221862				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.219684				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.233732				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 2.265864				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 2.232511				Client 4 should_send_params: True 


 Client 4 round 2 returning params_prime of size 4800816  

Client 4 round 2 - Evaluate on 5292 samples: Average loss: 2.2152, Accuracy: 41.86%

Client 4 round 3 (before train) - Evaluate on 5292 samples: Average loss: 2.2152, Accuracy: 41.86%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.222838				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.243571				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.212111				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.226526				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.226838				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.225570				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.234058				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.224297				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.234286				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.223726				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.238076				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.204379				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.212815				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.232343				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.201578				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.230118				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.204988				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.188174				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.207919				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.219107				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.220759				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.209498				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.214781				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.242738				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.184764				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 2.225500				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.208213				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.211750				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 2.221958				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 2.203865				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.216134				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 2.220935				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.213013				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 2.215610				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 2.211097				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 2.246248				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 2.219328				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 2.232853				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.210716				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.201178				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 2.210723				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.212837				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 2.216427				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 2.178715				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 2.185881				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 2.220075				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.194475				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.193675				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 2.198409				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 2.219097				Client 4 should_send_params: True 


 Client 4 round 3 returning params_prime of size 4800816  

Client 4 round 3 - Evaluate on 5292 samples: Average loss: 2.1886, Accuracy: 48.72%

Client 4 round 4 (before train) - Evaluate on 5292 samples: Average loss: 2.1886, Accuracy: 48.72%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.176788				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.196856				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.209414				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.211081				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.157546				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.211508				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.187396				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.218222				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.202402				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.221553				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.207890				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.204300				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.203535				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.182956				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.187541				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.223335				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.200785				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.185952				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.240361				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.236724				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.174732				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.204674				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.173267				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.182943				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.197338				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 2.183903				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.179787				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.197864				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 2.186134				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 2.189647				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.177218				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 2.166415				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.182724				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 2.206716				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 2.165038				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 2.192822				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 2.175848				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 2.158929				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.194483				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.159768				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 2.161128				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.191710				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 2.179493				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 2.179386				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 2.199872				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 2.178627				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.199926				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.199949				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 2.179024				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 2.175184				Client 4 should_send_params: True 


 Client 4 round 4 returning params_prime of size 4800816  

Client 4 round 4 - Evaluate on 5292 samples: Average loss: 2.1594, Accuracy: 55.67%

Client 4 round 5 (before train) - Evaluate on 5292 samples: Average loss: 2.1594, Accuracy: 55.67%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.146664				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.152770				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.160831				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.182309				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.190700				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.177092				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.210520				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.164742				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.184081				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.168713				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.186074				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.157603				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.193777				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.176721				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.161944				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.145819				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.205948				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.185980				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.173947				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.126175				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.189142				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.172138				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.161402				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.158140				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.182632				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 2.173244				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.155463				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.160008				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 2.202055				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 2.165158				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.161822				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 2.130783				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.167839				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 2.205691				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 2.183868				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 2.139388				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 2.177909				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 2.165209				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.167495				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.116500				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 2.162288				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.148463				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 2.157060				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 2.161600				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 2.145329				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 2.183821				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.179604				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.159104				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 2.169353				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 2.158771				Client 4 should_send_params: True 


 Client 4 round 5 returning params_prime of size 4800816  

Client 4 round 5 - Evaluate on 5292 samples: Average loss: 2.1276, Accuracy: 61.53%

Client 4 round 6 (before train) - Evaluate on 5292 samples: Average loss: 2.1276, Accuracy: 61.53%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.100405				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.142632				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.157054				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.140589				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.159090				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.157258				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.130663				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.111745				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.132728				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.125298				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.162570				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.158510				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.190820				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.125558				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.126552				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.137329				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.133722				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.136049				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.143561				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.131289				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.161534				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.130928				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.177125				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.147616				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.082378				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 2.151388				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.102705				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.090653				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 2.146024				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 2.115044				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.114006				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 2.107813				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.147057				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 2.080158				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 2.116553				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 2.132795				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 2.129480				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 2.083923				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.134387				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.166671				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 2.114436				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.115491				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 2.119572				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 2.145066				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 2.152913				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 2.121635				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.091286				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.055522				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 2.165957				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 2.147068				Client 4 should_send_params: True 


 Client 4 round 6 returning params_prime of size 4800816  

Client 4 round 6 - Evaluate on 5292 samples: Average loss: 2.0934, Accuracy: 65.74%

Client 4 round 7 (before train) - Evaluate on 5292 samples: Average loss: 2.0934, Accuracy: 65.74%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.110843				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.097433				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.081040				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.123499				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.075486				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.106413				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.120611				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.121757				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.093995				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.080327				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.080595				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.121582				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.106768				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.151842				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.123089				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.121168				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.081079				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.089349				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.092103				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.068449				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.054812				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.064253				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.092643				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.095538				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.113120				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 2.100736				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.088596				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.058456				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 2.101777				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 2.069173				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.097428				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 2.114842				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.141564				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 2.134782				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 2.118733				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 2.117941				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 2.074609				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 2.095869				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.114926				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.093324				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 2.120195				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.072282				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 2.058286				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 2.116081				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 2.111001				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 2.085719				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.060715				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.063217				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 2.074666				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 2.067729				Client 4 should_send_params: False 


 Client 4 round 7 returning params_prime of size 169  

Client 4 round 7 - Evaluate on 5292 samples: Average loss: 2.0570, Accuracy: 67.93%

Client 4 round 8 (before train) - Evaluate on 5292 samples: Average loss: 2.0570, Accuracy: 67.93%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.092703				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.110917				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.093263				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.043380				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.078738				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.062200				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.057002				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.096748				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.090927				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.035806				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.062636				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.055706				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.060954				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.091649				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.055258				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.069626				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.069683				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.088049				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.094994				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.057841				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.061839				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.005597				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.092249				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.032487				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.046737				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 2.105539				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.060846				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.068043				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 2.031109				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 2.050395				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.020196				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 2.022271				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.045670				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 2.046034				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 2.066841				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 2.105059				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 2.040094				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 2.024168				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.031426				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.058604				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 2.080564				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.003104				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 2.001335				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 2.104397				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 2.105948				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.983818				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.076693				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.062553				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 2.123045				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 2.079678				Client 4 should_send_params: False 


 Client 4 round 8 returning params_prime of size 169  

Client 4 round 8 - Evaluate on 5292 samples: Average loss: 2.0187, Accuracy: 69.35%

Client 4 round 9 (before train) - Evaluate on 5292 samples: Average loss: 2.0187, Accuracy: 69.35%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.078135				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.084918				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.043162				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.046018				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.990758				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.109293				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.049495				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.044051				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.048416				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.056170				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.061273				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.030314				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.062828				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.014011				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.038679				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.071781				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.036306				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.041818				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.032888				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.064436				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.007245				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.050393				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.097819				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.018991				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 2.041268				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.992186				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.026098				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.015070				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.979015				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 2.015276				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.075061				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 2.043583				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.027614				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 2.027888				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.996296				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 2.028679				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 2.042606				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.987802				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.036069				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.005936				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 2.002765				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.011095				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.952821				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.978061				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 2.004833				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 2.046744				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.051299				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.017602				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.966621				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.995996				Client 4 should_send_params: False 


 Client 4 round 9 returning params_prime of size 169  

Client 4 round 9 - Evaluate on 5292 samples: Average loss: 1.9788, Accuracy: 70.03%

Client 4 round 10 (before train) - Evaluate on 5292 samples: Average loss: 1.9788, Accuracy: 70.03%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.971415				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.015464				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.992371				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.025639				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.056108				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.032409				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.010707				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.012950				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.033530				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.987623				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.001140				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.994797				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.063087				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.960203				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.993500				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.006197				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.020906				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.984776				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.008010				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.970205				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.981334				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.988555				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.933670				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.957978				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.995949				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 2.021822				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 2.001426				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 2.004585				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.938104				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.990742				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.949081				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.975114				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 2.024717				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.965884				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 2.021645				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.896274				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.993963				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 2.028571				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 2.027865				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 2.004859				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.993304				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.008483				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 2.007253				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.968048				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.953650				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.935401				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.028552				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.940117				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.980325				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.990657				Client 4 should_send_params: False 


 Client 4 round 10 returning params_prime of size 169  

Client 4 round 10 - Evaluate on 5292 samples: Average loss: 1.9369, Accuracy: 70.54%

Client 4 round 11 (before train) - Evaluate on 5292 samples: Average loss: 1.9369, Accuracy: 70.54%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.971838				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.937831				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.948024				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.913590				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.969596				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.927120				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.955718				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.046244				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.004385				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.010060				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.925596				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.007012				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.977658				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.895336				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.010325				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.957730				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.967996				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.955248				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.895827				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.963118				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.978809				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.928280				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.952499				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.892833				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.961376				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.993159				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.948333				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.968483				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.971064				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.937729				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 2.020004				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.918374				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.945835				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.994456				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.933689				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.862762				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.940317				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.955145				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.935769				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.953014				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.934842				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 2.007349				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.970046				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.948595				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.869830				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.990241				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 2.006915				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 2.006019				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.869751				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.911999				Client 4 should_send_params: True 


 Client 4 round 11 returning params_prime of size 4800816  

Client 4 round 11 - Evaluate on 5292 samples: Average loss: 1.8934, Accuracy: 71.16%

Client 4 round 12 (before train) - Evaluate on 5292 samples: Average loss: 1.8934, Accuracy: 71.16%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.971590				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.969701				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.905455				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.902447				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.929280				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.983547				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.944275				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 1.916536				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 1.809761				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.866194				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.959277				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.952189				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.991802				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.870582				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.970327				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.871733				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.930809				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.856624				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.909958				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.989263				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.925198				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.840102				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.922927				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.844753				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.928635				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.884470				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.878430				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.976807				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.909401				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.902423				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.951287				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.926504				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.846442				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.927680				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.917142				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.854968				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.901162				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.972246				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.877324				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.938670				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.938962				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.794645				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.901104				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.883050				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.927654				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.821173				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.873091				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.913761				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.885018				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.823962				Client 4 should_send_params: False 


 Client 4 round 12 returning params_prime of size 169  

Client 4 round 12 - Evaluate on 5292 samples: Average loss: 1.8478, Accuracy: 71.56%

Client 4 round 13 (before train) - Evaluate on 5292 samples: Average loss: 1.8478, Accuracy: 71.56%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.854697				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.884943				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.857199				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.800712				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.852337				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.815111				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.889743				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 1.876395				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 1.870681				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.834301				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.861787				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.840637				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.866666				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.941664				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.883584				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.938859				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.877588				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.861803				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.908959				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.865909				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.885314				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.867122				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.887914				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.909187				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.855885				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.856989				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.839743				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.833763				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.873607				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.857675				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.884246				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.832684				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.920977				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.781149				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.856955				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.874316				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.781649				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.820811				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.875437				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.810528				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.848317				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.851394				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.847878				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.841742				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.815866				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.902632				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.831869				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.897405				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.747420				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.880629				Client 4 should_send_params: False 


 Client 4 round 13 returning params_prime of size 169  

Client 4 round 13 - Evaluate on 5292 samples: Average loss: 1.8009, Accuracy: 71.96%

Client 4 round 14 (before train) - Evaluate on 5292 samples: Average loss: 1.8009, Accuracy: 71.96%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.894377				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.912388				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.881654				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.844455				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.849146				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.875302				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.820808				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 1.838913				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 1.924098				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.826669				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.825188				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.851547				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.793840				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.875413				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.818950				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.812265				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.915466				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.852167				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.803041				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.824902				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.803210				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.848991				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.809143				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.848487				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.801093				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.830117				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.802792				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.797893				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.864606				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.803461				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.804698				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.770617				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.810044				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.838322				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.801091				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.726921				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.824907				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.803516				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.825063				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.781066				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.775528				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.895325				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.820656				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.829895				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.844031				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.719249				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.800813				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.728739				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.800986				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.838632				Client 4 should_send_params: True 


 Client 4 round 14 returning params_prime of size 4800816  

Client 4 round 14 - Evaluate on 5292 samples: Average loss: 1.7526, Accuracy: 72.75%

Client 4 round 15 (before train) - Evaluate on 5292 samples: Average loss: 1.7526, Accuracy: 72.75%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.766365				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.826203				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.803818				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.827533				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.739171				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.914090				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.792609				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 1.787865				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 1.880456				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.845560				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.756362				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.723018				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.829406				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.820356				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.812365				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.733625				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.818612				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.751087				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.818291				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.726691				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.790884				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.802844				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.713900				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.806513				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.769894				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.790496				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.875698				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.771829				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.836603				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.875540				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.724178				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.830070				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.711961				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.799061				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.848533				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.781877				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.739429				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.687125				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.785727				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.786182				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.735875				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.838061				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.751526				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.711320				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.740701				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.761389				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.729240				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.787778				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.741952				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.692497				Client 4 should_send_params: False 


 Client 4 round 15 returning params_prime of size 169  

Client 4 round 15 - Evaluate on 5292 samples: Average loss: 1.7031, Accuracy: 73.19%

Client 4 round 16 (before train) - Evaluate on 5292 samples: Average loss: 1.7031, Accuracy: 73.19%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.823900				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.768026				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.666576				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.745455				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.795848				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.801232				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.728856				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 1.676116				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 1.690739				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.733267				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.803366				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.706608				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.713633				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.722995				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.777757				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.730204				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.708807				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.807302				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.905907				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.750299				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.723905				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.635900				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.754509				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.847541				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.800167				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.719809				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.748466				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.820311				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.733655				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.755352				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.692039				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.681276				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.727547				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.737173				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.720990				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.645753				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.650374				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.735958				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.734212				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.768971				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.794351				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.610792				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.722503				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.712639				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.708833				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.716608				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.727970				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.693523				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.710207				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.708549				Client 4 should_send_params: False 


 Client 4 round 16 returning params_prime of size 169  

Client 4 round 16 - Evaluate on 5292 samples: Average loss: 1.6526, Accuracy: 73.87%

Client 4 round 17 (before train) - Evaluate on 5292 samples: Average loss: 1.6526, Accuracy: 73.87%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.672663				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.780793				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.671576				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.759933				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.742491				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.703572				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.638670				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 1.771819				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 1.623671				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.699977				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.772026				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.704192				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.670734				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.695930				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.740255				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.689792				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.639147				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.646861				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.656762				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.738537				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.672314				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.605305				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.742248				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.621669				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.729123				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.728279				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.610432				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.693768				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.708488				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.587431				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.771430				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.701021				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.648686				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.725353				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.702598				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.703460				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.747872				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.752225				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.664750				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.683800				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.737580				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.721442				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.771155				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.633321				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.650161				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.792262				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.622802				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.721992				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.682780				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.692553				Client 4 should_send_params: True 


 Client 4 round 17 returning params_prime of size 4800816  

Client 4 round 17 - Evaluate on 5292 samples: Average loss: 1.6017, Accuracy: 74.62%

Client 4 round 18 (before train) - Evaluate on 5292 samples: Average loss: 1.6017, Accuracy: 74.62%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.647159				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.764753				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.699519				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.655342				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.664230				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.684581				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.660656				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 1.762151				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 1.684551				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.673395				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.681201				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.668832				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.721348				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.602431				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.543518				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.649909				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.751218				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.655189				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.638041				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.682895				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.665180				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.769799				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.702193				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.679511				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.685825				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.744565				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.714191				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.710891				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.614284				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.620054				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.680849				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.475223				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.615979				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.663301				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.621435				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.536774				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.673695				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.631330				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.710427				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.620961				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.627347				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.698962				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.655532				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.732203				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.616807				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.556287				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.492676				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.602704				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.723958				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.555541				Client 4 should_send_params: False 


 Client 4 round 18 returning params_prime of size 169  

Client 4 round 18 - Evaluate on 5292 samples: Average loss: 1.5513, Accuracy: 75.47%

Client 4 round 19 (before train) - Evaluate on 5292 samples: Average loss: 1.5513, Accuracy: 75.47%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.638936				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.636690				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.729598				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.626941				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.650361				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.649823				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.581001				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 1.643714				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 1.551227				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.552436				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.752289				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.544789				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.595909				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.602541				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.618492				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.603325				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.592412				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.577071				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.595229				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.593988				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.649763				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.631352				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.644915				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.532875				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.610183				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.564636				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.616572				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.582104				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.656450				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.634113				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.545913				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.577055				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.545168				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.523147				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.679812				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.653534				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.560631				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.604878				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.532126				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.643868				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.585104				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.697659				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.696815				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.550569				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.624799				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.485510				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.562382				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.678439				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.601358				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.616085				Client 4 should_send_params: False 


 Client 4 round 19 returning params_prime of size 169  

Client 4 round 19 - Evaluate on 5292 samples: Average loss: 1.5011, Accuracy: 76.30%

Client 4 round 20 (before train) - Evaluate on 5292 samples: Average loss: 1.5011, Accuracy: 76.30%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 1.660807				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 1.652097				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 1.623758				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 1.605694				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.521857				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 1.551146				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 1.523065				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 1.542866				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 1.545132				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 1.537902				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 1.514652				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 1.572509				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 1.483909				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 1.644444				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 1.678514				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 1.490472				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 1.525569				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 1.429701				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 1.495181				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.578815				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 1.538557				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 1.547754				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 1.595297				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 1.623114				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.591075				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.639019				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.552472				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.597118				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.559302				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.660148				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.488031				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.460927				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.677096				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.528355				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.448245				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.539400				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.596057				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.610732				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.650357				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.476674				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.555795				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.508478				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.626098				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.543533				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.547668				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.561007				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.480793				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.468470				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.562835				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.539826				DEBUG flower 2022-04-17 21:47:12,180 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-04-17 21:47:12,180 | app.py:72 | Disconnect and shut down
Client 4 should_send_params: False 


 Client 4 round 20 returning params_prime of size 169  

Client 4 round 20 - Evaluate on 5292 samples: Average loss: 1.4509, Accuracy: 77.10%

