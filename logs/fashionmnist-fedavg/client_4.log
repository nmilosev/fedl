DEBUG flower 2022-04-19 14:47:47,207 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2022-04-19 14:47:47,208 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2022-04-19 14:47:47,208 | app.py:61 | Opened (insecure) gRPC connection
Client CID: 4
[28016 28321 47294 53184]
[1344 3713 4197 4708]
Client 4 round 1 (before train) - Evaluate on 5292 samples: Average loss: 2.3049, Accuracy: 9.50%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 2.318001				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 2.291173				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 2.277402				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 2.286156				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 2.263872				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 2.267566				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 2.253194				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 2.249565				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 2.259290				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 2.233796				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 2.209438				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 2.213091				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 2.182771				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 2.183291				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 2.182456				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 2.151742				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 2.112853				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 2.115891				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 2.112065				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 2.150278				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 2.017324				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 2.078066				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 2.015726				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 2.043916				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 1.935189				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 1.943494				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 1.872354				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.898665				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 1.912870				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 1.865867				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 1.829619				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 1.757272				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 1.803464				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 1.803261				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 1.700502				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 1.673710				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 1.707312				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 1.615401				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 1.612440				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 1.638021				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 1.600064				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 1.526380				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 1.507901				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 1.688435				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 1.530839				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.591109				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 1.583977				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 1.441530				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 1.498719				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 1.492136				
 Client 4 round 1 returning params_prime of size 4800816  

Client 4 round 1 - Evaluate on 5292 samples: Average loss: 0.7834, Accuracy: 73.54%

Client 4 round 2 (before train) - Evaluate on 5292 samples: Average loss: 0.7834, Accuracy: 73.54%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.867892				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.840571				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.681556				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.915040				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 1.020075				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.819496				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.882100				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.918267				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.842616				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.796853				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.866317				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.810331				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.742684				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.889210				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.891756				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.965086				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.738948				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.949573				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.717017				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 1.146230				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.698155				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.754473				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.816911				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.756181				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.789708				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.785856				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.876553				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 1.056892				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.882140				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.878925				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.660271				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.982506				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.801544				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.786334				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.759093				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.916407				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.823946				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.873457				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.778120				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.799890				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.862059				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.859663				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.645224				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.790495				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.795923				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 1.064228				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.592024				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.671651				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.712142				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.735726				
 Client 4 round 2 returning params_prime of size 4800816  

Client 4 round 2 - Evaluate on 5292 samples: Average loss: 0.6176, Accuracy: 77.25%

Client 4 round 3 (before train) - Evaluate on 5292 samples: Average loss: 0.6176, Accuracy: 77.25%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.441696				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.894771				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.721908				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.968565				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.787951				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.717171				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.732329				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.600708				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.678751				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.651357				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.749652				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.739612				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.728094				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.663276				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.637461				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.709768				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.620238				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.594395				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.536361				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.611877				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.636123				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.850400				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.588140				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.449106				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.619231				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.643761				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.684761				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.572273				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.515036				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.651460				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.822401				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.633048				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.704809				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.590754				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.558177				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.603567				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.701902				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.589222				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.795230				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.737267				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.673484				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.653496				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.731055				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.848826				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.450146				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.383136				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.717520				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.693582				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.751022				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.519112				
 Client 4 round 3 returning params_prime of size 4800816  

Client 4 round 3 - Evaluate on 5292 samples: Average loss: 0.5596, Accuracy: 79.08%

Client 4 round 4 (before train) - Evaluate on 5292 samples: Average loss: 0.5596, Accuracy: 79.08%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.592564				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.515432				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.640793				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.850239				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.659929				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.441383				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.729191				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.493366				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.684517				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.546839				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.454440				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.378148				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.672450				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.584403				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.684390				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.641117				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.631457				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.516873				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.615513				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.494700				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.741984				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.714587				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.680397				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.508666				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.528248				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.654814				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.684920				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.521430				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.758333				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.663907				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.566628				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.597911				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.546592				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.637691				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.592015				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.494681				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.688858				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.583162				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.445827				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.691736				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.542064				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.496553				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.634742				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.581708				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.574669				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.588013				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.616813				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.627919				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.712048				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.752042				
 Client 4 round 4 returning params_prime of size 4800816  

Client 4 round 4 - Evaluate on 5292 samples: Average loss: 0.5222, Accuracy: 80.91%

Client 4 round 5 (before train) - Evaluate on 5292 samples: Average loss: 0.5222, Accuracy: 80.91%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.486851				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.471388				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.725304				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.524742				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.852312				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.504051				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.740937				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.726047				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.682824				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.542867				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.595363				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.599903				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.467766				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.395366				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.595253				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.601251				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.633552				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.583250				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.607489				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.836351				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.692800				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.414391				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.612770				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.500576				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.476972				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.583050				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.593009				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.628428				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.494034				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.577949				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.512631				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.618281				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.398743				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.625391				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.789118				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.530058				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.457411				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.646417				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.579142				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.732374				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.809343				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.471529				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.576760				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.511454				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.625566				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.590406				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.645947				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.463309				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.466044				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.888760				
 Client 4 round 5 returning params_prime of size 4800816  

Client 4 round 5 - Evaluate on 5292 samples: Average loss: 0.4935, Accuracy: 82.22%

Client 4 round 6 (before train) - Evaluate on 5292 samples: Average loss: 0.4935, Accuracy: 82.22%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.535312				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.471995				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.392448				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.494321				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.492615				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.526615				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.634640				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.398662				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.593221				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.540377				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.592246				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.586094				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.447127				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.574774				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.549863				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.413529				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.687974				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.297374				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.528770				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.640694				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.455642				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.567702				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.518804				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.562867				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.527453				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.655024				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.453356				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.418652				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.537655				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.628404				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.585036				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.643640				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.431252				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.531561				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.469852				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.512163				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.431687				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.480446				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.528533				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.477826				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.594480				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.647151				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.699828				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.583916				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.741593				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.509623				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.482856				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.447667				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.424125				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.538961				
 Client 4 round 6 returning params_prime of size 4800816  

Client 4 round 6 - Evaluate on 5292 samples: Average loss: 0.4730, Accuracy: 83.01%

Client 4 round 7 (before train) - Evaluate on 5292 samples: Average loss: 0.4730, Accuracy: 83.01%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.519330				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.363264				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.607244				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.571869				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.479989				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.500286				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.493069				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.474052				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.727892				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.719316				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.567090				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.525825				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.807431				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.508429				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.610555				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.441062				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.732722				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.370001				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.422593				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.522608				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.507480				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.573883				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.567602				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.380950				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.490611				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.499738				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.502243				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.429774				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.508394				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.372108				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.565495				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.441901				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.445008				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.358819				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.508596				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.552911				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.402062				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.410829				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.517141				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.713354				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.446549				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.351365				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.304404				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.576634				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.540022				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.435664				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.505684				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.569723				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.544809				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.696893				
 Client 4 round 7 returning params_prime of size 4800816  

Client 4 round 7 - Evaluate on 5292 samples: Average loss: 0.4560, Accuracy: 83.69%

Client 4 round 8 (before train) - Evaluate on 5292 samples: Average loss: 0.4560, Accuracy: 83.69%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.311124				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.587388				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.348443				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.437120				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.523969				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.393702				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.448748				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.809009				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.370011				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.502007				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.528723				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.480792				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.484024				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.493061				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.259485				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.417270				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.458206				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.570400				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.304274				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.540171				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.541212				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.350055				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.519344				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.407140				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.609856				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.690998				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.369551				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.626213				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.486486				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.621348				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.317852				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.551955				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.384990				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.745006				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.421001				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.468717				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.451385				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.436213				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.564470				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.572285				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.448061				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.680280				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.436754				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.701285				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.411480				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.469087				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.541529				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.521839				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.572548				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.716475				
 Client 4 round 8 returning params_prime of size 4800816  

Client 4 round 8 - Evaluate on 5292 samples: Average loss: 0.4430, Accuracy: 84.13%

Client 4 round 9 (before train) - Evaluate on 5292 samples: Average loss: 0.4430, Accuracy: 84.13%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.578450				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.608536				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.525052				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.444867				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.377444				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.543674				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.393424				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.448316				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.357623				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.567234				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.453024				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.308112				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.541316				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.467421				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.638503				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.487958				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.395753				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.458999				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.399906				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.462511				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.482682				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.528677				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.470098				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.376737				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.574453				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.391553				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.552668				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.545593				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.556220				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.385276				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.532819				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.431133				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.372047				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.350974				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.417959				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.412454				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.558588				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.382602				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.550349				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.353212				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.519925				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.462145				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.371101				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.612369				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.378646				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.598449				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.479305				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.400567				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.538859				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.613860				
 Client 4 round 9 returning params_prime of size 4800816  

Client 4 round 9 - Evaluate on 5292 samples: Average loss: 0.4319, Accuracy: 84.52%

Client 4 round 10 (before train) - Evaluate on 5292 samples: Average loss: 0.4319, Accuracy: 84.52%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.504564				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.574954				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.713769				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.652229				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.505803				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.560066				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.533124				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.557089				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.465525				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.439963				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.580237				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.572177				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.410238				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.435013				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.326533				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.429300				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.658302				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.343468				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.574821				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.430998				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.733055				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.396452				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.393377				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.362898				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.459664				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.343026				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.353012				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.427609				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.305799				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.606142				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.340071				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.421945				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.444944				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.582002				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.280801				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.524054				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.545619				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.404435				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.459170				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.270159				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.358653				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.431271				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.380107				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.333365				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.412168				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.335412				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.396656				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.749082				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.432162				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.557552				
 Client 4 round 10 returning params_prime of size 4800816  

Client 4 round 10 - Evaluate on 5292 samples: Average loss: 0.4218, Accuracy: 85.13%

Client 4 round 11 (before train) - Evaluate on 5292 samples: Average loss: 0.4218, Accuracy: 85.13%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.439406				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.589457				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.369929				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.444519				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.305388				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.607644				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.633790				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.528831				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.430310				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.399688				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.366934				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.403412				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.675662				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.492670				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.593481				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.676231				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.368372				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.398853				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.479646				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.471980				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.448347				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.514807				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.417064				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.360992				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.445895				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.425953				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.409627				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.546423				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.576137				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.682511				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.445710				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.366480				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.411235				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.478454				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.559792				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.569037				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.531349				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.357287				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.554850				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.692834				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.459027				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.592450				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.637310				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.410715				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.576278				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.630676				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.407664				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.412640				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.543820				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.410440				
 Client 4 round 11 returning params_prime of size 4800816  

Client 4 round 11 - Evaluate on 5292 samples: Average loss: 0.4131, Accuracy: 85.28%

Client 4 round 12 (before train) - Evaluate on 5292 samples: Average loss: 0.4131, Accuracy: 85.28%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.443590				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.488469				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.545080				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.382041				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.360965				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.407771				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.620797				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.787314				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.336945				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.483419				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.436419				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.772403				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.467201				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.354246				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.432569				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.352460				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.371770				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.418897				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.412245				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.507507				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.393118				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.473158				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.374657				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.418559				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.500858				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.463524				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.316421				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.369447				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.437633				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.272643				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.328853				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.536804				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.570254				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.312162				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.279406				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.591425				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.494699				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.303402				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.388719				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.404786				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.396309				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.215632				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.359391				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.499729				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.497727				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.457090				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.340178				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.490093				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.525257				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.725796				
 Client 4 round 12 returning params_prime of size 4800816  

Client 4 round 12 - Evaluate on 5292 samples: Average loss: 0.4052, Accuracy: 85.39%

Client 4 round 13 (before train) - Evaluate on 5292 samples: Average loss: 0.4052, Accuracy: 85.39%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.347039				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.397053				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.464833				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.339329				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.398334				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.426143				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.369475				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.444093				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.341157				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.382141				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.454017				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.337512				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.476710				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.330008				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.470326				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.481709				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.497524				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.348088				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.478137				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.604113				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.341147				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.477154				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.381659				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.391050				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.337118				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.372040				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.435151				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.512693				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.374591				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.494230				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.598343				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.424854				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.294921				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.543474				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.351804				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.373314				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.554174				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.418626				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.541144				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.173450				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.359586				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.400367				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.368673				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.410355				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.594904				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.494943				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.494011				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.547919				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.365871				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.318294				
 Client 4 round 13 returning params_prime of size 4800816  

Client 4 round 13 - Evaluate on 5292 samples: Average loss: 0.3986, Accuracy: 85.58%

Client 4 round 14 (before train) - Evaluate on 5292 samples: Average loss: 0.3986, Accuracy: 85.58%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.548095				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.512986				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.233171				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.373902				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.536558				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.326514				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.209154				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.613694				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.605924				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.413517				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.449095				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.371311				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.380801				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.533918				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.521520				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.272521				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.389810				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.492060				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.463051				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.394180				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.531407				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.316141				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.395623				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.327288				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.498391				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.490269				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.285381				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.509601				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.361809				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.416846				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.608288				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.479492				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.500440				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.344094				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.431432				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.510528				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.444709				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.512078				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.434025				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.337482				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.375525				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.640661				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.539694				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.445010				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.359329				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.474909				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.543764				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.376573				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.487250				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.331771				
 Client 4 round 14 returning params_prime of size 4800816  

Client 4 round 14 - Evaluate on 5292 samples: Average loss: 0.3928, Accuracy: 85.98%

Client 4 round 15 (before train) - Evaluate on 5292 samples: Average loss: 0.3928, Accuracy: 85.98%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.494976				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.440239				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.191203				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.356743				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.262555				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.333775				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.315937				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.354841				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.319276				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.350239				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.515521				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.423030				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.514465				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.446029				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.359031				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.469564				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.441169				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.616607				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.460421				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.637144				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.464955				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.653572				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.536122				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.252519				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.299673				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.480327				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.552784				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.474885				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.275686				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.507979				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.290028				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.291161				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.466359				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.333694				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.478485				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.479274				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.291709				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.434223				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.426411				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.320084				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.335626				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.310215				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.407731				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.349422				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.458794				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.383854				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.486785				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.531718				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.454661				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.181897				
 Client 4 round 15 returning params_prime of size 4800816  

Client 4 round 15 - Evaluate on 5292 samples: Average loss: 0.3859, Accuracy: 86.19%

Client 4 round 16 (before train) - Evaluate on 5292 samples: Average loss: 0.3859, Accuracy: 86.19%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.620189				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.593818				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.311946				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.247532				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.465469				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.370225				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.405325				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.427218				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.375203				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.429674				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.326000				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.504951				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.343746				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.443178				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.194541				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.544476				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.382913				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.262692				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.320243				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.366844				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.313005				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.293664				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.513794				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.310189				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.345965				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.366487				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.417653				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.415404				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.487128				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.458779				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.297863				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.486332				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.474507				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.471992				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.209947				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.617404				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.407710				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.426809				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.604993				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.275804				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.424045				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.484497				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.442081				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.404092				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.320473				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.343209				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.515664				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.334593				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.335186				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.344230				
 Client 4 round 16 returning params_prime of size 4800816  

Client 4 round 16 - Evaluate on 5292 samples: Average loss: 0.3825, Accuracy: 86.34%

Client 4 round 17 (before train) - Evaluate on 5292 samples: Average loss: 0.3825, Accuracy: 86.34%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.463554				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.366933				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.557350				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.403779				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.308261				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.413056				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.727873				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.441034				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.439496				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.338865				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.419565				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.486969				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.268987				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.385356				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.539186				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.379314				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.344777				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.429883				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.337293				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.524108				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.255994				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.295855				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.408642				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.477660				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.427613				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.616920				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.615010				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.453280				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.477446				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.530229				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.448146				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.459642				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.388970				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.418001				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.569027				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.413461				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.301876				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.370680				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.378332				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.441893				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.510352				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.282192				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.453220				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.510276				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.239180				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.457561				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.454296				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.544095				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.349571				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.330674				
 Client 4 round 17 returning params_prime of size 4800816  

Client 4 round 17 - Evaluate on 5292 samples: Average loss: 0.3767, Accuracy: 86.51%

Client 4 round 18 (before train) - Evaluate on 5292 samples: Average loss: 0.3767, Accuracy: 86.51%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.296784				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.273446				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.343503				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.538635				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.503924				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.339660				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.535016				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.375588				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.347891				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.494291				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.342025				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.472822				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.203693				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.370402				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.545558				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.578560				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.300888				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.698454				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.565095				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.479841				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.574816				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.257232				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.419636				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.483297				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.380283				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.429997				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.326204				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.374435				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.520919				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.311431				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.508746				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.405845				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.489567				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.414576				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.423260				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.256913				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.329297				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.465925				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.453962				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.323780				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.310586				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.356883				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.520092				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.575408				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.329727				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.519668				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.486408				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.443894				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.468005				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.416493				
 Client 4 round 18 returning params_prime of size 4800816  

Client 4 round 18 - Evaluate on 5292 samples: Average loss: 0.3726, Accuracy: 86.75%

Client 4 round 19 (before train) - Evaluate on 5292 samples: Average loss: 0.3726, Accuracy: 86.75%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.582079				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.344900				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.455866				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.497517				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.437112				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.521617				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.296023				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.546946				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.367448				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.567723				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.391910				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.348014				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.367344				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.498791				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.308819				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.446707				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.349088				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.228705				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.504550				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.456707				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.483957				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.324209				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.298616				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.365658				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.369228				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.328373				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.465914				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.422409				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.373145				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.407124				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.389453				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.555278				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.289324				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.614457				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.507572				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.320567				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.425325				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.546922				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.492580				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.359212				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.447780				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.298056				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.309011				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.405288				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.370498				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.475510				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.355589				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.528516				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.553147				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.455394				
 Client 4 round 19 returning params_prime of size 4800816  

Client 4 round 19 - Evaluate on 5292 samples: Average loss: 0.3693, Accuracy: 86.75%

Client 4 round 20 (before train) - Evaluate on 5292 samples: Average loss: 0.3693, Accuracy: 86.75%

Training 5 epoch(s) w/ 107 mini-batches each

[client 4] Train Epoch: 0 [576/6848 (8%)] Loss: 0.435412				[client 4] Train Epoch: 0 [1216/6848 (18%)] Loss: 0.426475				[client 4] Train Epoch: 0 [1856/6848 (27%)] Loss: 0.376026				[client 4] Train Epoch: 0 [2496/6848 (36%)] Loss: 0.504894				[client 4] Train Epoch: 0 [3136/6848 (46%)] Loss: 0.483921				[client 4] Train Epoch: 0 [3776/6848 (55%)] Loss: 0.422544				[client 4] Train Epoch: 0 [4416/6848 (64%)] Loss: 0.362901				[client 4] Train Epoch: 0 [5056/6848 (74%)] Loss: 0.328736				[client 4] Train Epoch: 0 [5696/6848 (83%)] Loss: 0.366614				[client 4] Train Epoch: 0 [6336/6848 (93%)] Loss: 0.407627				
[client 4] Train Epoch: 1 [576/6848 (8%)] Loss: 0.364001				[client 4] Train Epoch: 1 [1216/6848 (18%)] Loss: 0.205003				[client 4] Train Epoch: 1 [1856/6848 (27%)] Loss: 0.378500				[client 4] Train Epoch: 1 [2496/6848 (36%)] Loss: 0.278750				[client 4] Train Epoch: 1 [3136/6848 (46%)] Loss: 0.457851				[client 4] Train Epoch: 1 [3776/6848 (55%)] Loss: 0.450709				[client 4] Train Epoch: 1 [4416/6848 (64%)] Loss: 0.245444				[client 4] Train Epoch: 1 [5056/6848 (74%)] Loss: 0.453145				[client 4] Train Epoch: 1 [5696/6848 (83%)] Loss: 0.353392				[client 4] Train Epoch: 1 [6336/6848 (93%)] Loss: 0.445755				
[client 4] Train Epoch: 2 [576/6848 (8%)] Loss: 0.359415				[client 4] Train Epoch: 2 [1216/6848 (18%)] Loss: 0.248760				[client 4] Train Epoch: 2 [1856/6848 (27%)] Loss: 0.353295				[client 4] Train Epoch: 2 [2496/6848 (36%)] Loss: 0.300647				[client 4] Train Epoch: 2 [3136/6848 (46%)] Loss: 0.322129				[client 4] Train Epoch: 2 [3776/6848 (55%)] Loss: 0.386138				[client 4] Train Epoch: 2 [4416/6848 (64%)] Loss: 0.421700				[client 4] Train Epoch: 2 [5056/6848 (74%)] Loss: 0.359882				[client 4] Train Epoch: 2 [5696/6848 (83%)] Loss: 0.490736				[client 4] Train Epoch: 2 [6336/6848 (93%)] Loss: 0.498856				
[client 4] Train Epoch: 3 [576/6848 (8%)] Loss: 0.371349				[client 4] Train Epoch: 3 [1216/6848 (18%)] Loss: 0.308080				[client 4] Train Epoch: 3 [1856/6848 (27%)] Loss: 0.279772				[client 4] Train Epoch: 3 [2496/6848 (36%)] Loss: 0.382323				[client 4] Train Epoch: 3 [3136/6848 (46%)] Loss: 0.489397				[client 4] Train Epoch: 3 [3776/6848 (55%)] Loss: 0.311705				[client 4] Train Epoch: 3 [4416/6848 (64%)] Loss: 0.487048				[client 4] Train Epoch: 3 [5056/6848 (74%)] Loss: 0.251107				[client 4] Train Epoch: 3 [5696/6848 (83%)] Loss: 0.511876				[client 4] Train Epoch: 3 [6336/6848 (93%)] Loss: 0.485283				
[client 4] Train Epoch: 4 [576/6848 (8%)] Loss: 0.449409				[client 4] Train Epoch: 4 [1216/6848 (18%)] Loss: 0.397506				[client 4] Train Epoch: 4 [1856/6848 (27%)] Loss: 0.271272				[client 4] Train Epoch: 4 [2496/6848 (36%)] Loss: 0.307032				[client 4] Train Epoch: 4 [3136/6848 (46%)] Loss: 0.228097				[client 4] Train Epoch: 4 [3776/6848 (55%)] Loss: 0.204927				[client 4] Train Epoch: 4 [4416/6848 (64%)] Loss: 0.256145				[client 4] Train Epoch: 4 [5056/6848 (74%)] Loss: 0.358488				[client 4] Train Epoch: 4 [5696/6848 (83%)] Loss: 0.305165				[client 4] Train Epoch: 4 [6336/6848 (93%)] Loss: 0.239023				DEBUG flower 2022-04-19 16:20:39,547 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-04-19 16:20:39,548 | app.py:72 | Disconnect and shut down

 Client 4 round 20 returning params_prime of size 4800816  

Client 4 round 20 - Evaluate on 5292 samples: Average loss: 0.3662, Accuracy: 86.83%

