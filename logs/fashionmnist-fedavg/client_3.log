DEBUG flower 2022-04-19 14:47:47,092 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2022-04-19 14:47:47,092 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2022-04-19 14:47:47,094 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2022-04-19 14:47:47,104 | app.py:61 | Opened (insecure) gRPC connection
Client CID: 3
[28016 28321 47294 53184]
[1344 3713 4197 4708]
Client 3 round 1 (before train) - Evaluate on 511 samples: Average loss: 2.3006, Accuracy: 7.05%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 2.306591				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 2.284963				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 2.290417				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 2.275511				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 2.274853				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 2.240243				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 2.261022				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 2.244611				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 2.221807				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 2.252751				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 2.204491				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 2.201359				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 2.214718				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 2.199114				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 2.161061				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 2.125506				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 2.135334				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 2.131681				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 2.099122				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 2.113439				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 2.126098				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 2.051188				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 2.066070				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 1.996271				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 1.982852				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 1.991858				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 2.039195				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 1.943173				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 1.864890				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.955577				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 1.861663				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 1.832815				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 1.771187				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 1.766534				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 1.898514				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 1.766286				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 1.712879				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 1.722081				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 1.679408				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 1.639326				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 1.543823				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 1.609261				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 1.653127				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 1.670934				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 1.617644				
 Client 3 round 1 returning params_prime of size 4800816  

Client 3 round 1 - Evaluate on 511 samples: Average loss: 0.7592, Accuracy: 74.36%

Client 3 round 2 (before train) - Evaluate on 511 samples: Average loss: 0.7592, Accuracy: 74.36%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.896840				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.854455				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 1.070140				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.958833				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.838165				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.826167				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.942239				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.797498				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.851543				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.741998				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.769760				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.922392				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.758737				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.990784				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.963035				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 1.007056				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.875970				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.855803				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 1.084769				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.824593				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.872947				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.724302				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.788399				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.624062				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.720354				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.900937				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.737601				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.777767				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.833268				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 1.010862				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.868679				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.853181				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.688264				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.753060				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.711302				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.852390				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.732117				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.723539				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.636826				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.716752				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.762570				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.738538				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.703074				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.912970				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.759963				
 Client 3 round 2 returning params_prime of size 4800816  

Client 3 round 2 - Evaluate on 511 samples: Average loss: 0.5982, Accuracy: 77.10%

Client 3 round 3 (before train) - Evaluate on 511 samples: Average loss: 0.5982, Accuracy: 77.10%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.692771				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.919071				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.595598				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.495352				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.562973				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.613059				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.653628				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.489563				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.691090				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.877358				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.726367				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.641055				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.732051				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.615094				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.627962				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.632843				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.567347				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.604417				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.776276				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.659391				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.766208				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.688414				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.679180				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.603006				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.793744				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.853854				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.698627				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.718880				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.688696				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.749311				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.562454				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.741750				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.716155				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.567192				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.855457				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.707114				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.761752				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.778288				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.572565				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.699283				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.601812				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.693990				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.840500				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.506422				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.642036				
 Client 3 round 3 returning params_prime of size 4800816  

Client 3 round 3 - Evaluate on 511 samples: Average loss: 0.5452, Accuracy: 79.84%

Client 3 round 4 (before train) - Evaluate on 511 samples: Average loss: 0.5452, Accuracy: 79.84%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.423693				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.583040				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.781267				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.404419				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.604152				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.722892				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.478242				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.579033				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.574205				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.640215				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.575387				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.433214				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.510145				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.704944				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.549668				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.629957				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.640834				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.481295				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.812539				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.610586				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.654452				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.752376				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.714246				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.747519				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.686205				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.377508				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.738561				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.606588				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.325552				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.474377				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.680912				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.534481				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.400142				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.486372				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.565533				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.729370				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.695000				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.618053				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.761411				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.396479				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.637492				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.401694				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.700432				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.470284				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.794503				
 Client 3 round 4 returning params_prime of size 4800816  

Client 3 round 4 - Evaluate on 511 samples: Average loss: 0.5106, Accuracy: 81.60%

Client 3 round 5 (before train) - Evaluate on 511 samples: Average loss: 0.5106, Accuracy: 81.60%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.625868				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.561303				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.768026				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.687984				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.637093				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.554300				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.460136				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.514769				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.437266				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.638956				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.683175				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.820193				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.608879				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.583481				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.460557				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.652912				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.543854				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.531435				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.634091				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.695683				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.553885				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.586982				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.470823				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.431671				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.651722				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.555876				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.529427				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.747136				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.501625				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.506482				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.436241				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.740336				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.532767				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.504980				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.629956				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.443297				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.632767				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.536629				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.368723				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.537677				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.394188				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.609750				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.592693				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.494687				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.512076				
 Client 3 round 5 returning params_prime of size 4800816  

Client 3 round 5 - Evaluate on 511 samples: Average loss: 0.4869, Accuracy: 82.19%

Client 3 round 6 (before train) - Evaluate on 511 samples: Average loss: 0.4869, Accuracy: 82.19%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.323925				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.538233				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.430681				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.622654				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.569037				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.527815				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.559062				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.615642				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.562815				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.382163				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.511290				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.538689				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.465374				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.468458				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.605025				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.580735				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.607486				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.353687				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.516290				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.301131				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.496002				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.371239				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.503410				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.485509				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.538366				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.594002				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.497608				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.492982				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.369798				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.415643				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.410250				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.275082				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.633166				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.565968				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.520046				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.422062				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.449910				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.321648				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.365051				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.423479				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.407418				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.636136				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.568213				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.519422				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.439637				
 Client 3 round 6 returning params_prime of size 4800816  

Client 3 round 6 - Evaluate on 511 samples: Average loss: 0.4726, Accuracy: 83.37%

Client 3 round 7 (before train) - Evaluate on 511 samples: Average loss: 0.4726, Accuracy: 83.37%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.303672				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.550429				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.410597				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.495620				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.565448				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.601583				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.493160				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.626678				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.335841				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.583896				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.496572				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.519709				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.548920				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.531872				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.468946				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.393473				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.475052				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.733621				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.487253				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.520869				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.659431				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.680036				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.485716				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.479052				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.474636				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.467158				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.600534				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.479861				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.568571				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.618071				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.502041				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.394295				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.500007				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.365349				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.362999				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.485092				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.786026				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.488929				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.387801				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.554764				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.463849				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.391501				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.521238				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.545876				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.407909				
 Client 3 round 7 returning params_prime of size 4800816  

Client 3 round 7 - Evaluate on 511 samples: Average loss: 0.4584, Accuracy: 83.76%

Client 3 round 8 (before train) - Evaluate on 511 samples: Average loss: 0.4584, Accuracy: 83.76%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.430129				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.495320				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.371399				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.679521				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.437374				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.470357				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.363438				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.358719				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.361302				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.556791				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.517616				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.498973				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.358461				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.511320				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.402061				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.557805				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.425785				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.667756				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.626827				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.382159				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.470002				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.800563				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.286926				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.524969				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.570021				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.289194				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.495772				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.363828				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.646846				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.589736				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.678871				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.440561				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.465245				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.498969				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.378050				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.552916				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.458911				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.397501				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.376277				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.652353				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.534295				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.453642				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.381278				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.509416				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.489486				
 Client 3 round 8 returning params_prime of size 4800816  

Client 3 round 8 - Evaluate on 511 samples: Average loss: 0.4478, Accuracy: 84.54%

Client 3 round 9 (before train) - Evaluate on 511 samples: Average loss: 0.4478, Accuracy: 84.54%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.416480				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.270904				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.453868				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.443173				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.467179				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.534898				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.527518				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.513327				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.552748				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.536129				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.336359				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.518891				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.497405				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.619411				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.389830				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.687151				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.399355				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.550981				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.499078				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.420414				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.317098				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.259946				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.650368				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.556299				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.629942				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.552972				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.538774				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.458294				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.320095				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.425941				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.398678				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.376172				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.486819				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.380878				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.550896				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.362682				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.493934				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.441801				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.437204				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.397508				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.500344				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.470687				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.635611				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.626849				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.401376				
 Client 3 round 9 returning params_prime of size 4800816  

Client 3 round 9 - Evaluate on 511 samples: Average loss: 0.4407, Accuracy: 84.74%

Client 3 round 10 (before train) - Evaluate on 511 samples: Average loss: 0.4407, Accuracy: 84.74%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.449792				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.398004				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.493200				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.292755				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.373481				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.714894				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.500931				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.399399				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.515175				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.548816				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.572710				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.340447				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.567705				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.428679				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.327636				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.281594				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.424996				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.539318				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.505362				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.334690				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.462926				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.452013				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.454268				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.440929				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.369867				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.475037				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.534879				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.536634				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.501833				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.514400				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.416122				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.410567				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.372840				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.350941				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.512951				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.321867				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.431839				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.497192				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.428783				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.267300				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.453533				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.465535				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.299360				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.348677				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.453445				
 Client 3 round 10 returning params_prime of size 4800816  

Client 3 round 10 - Evaluate on 511 samples: Average loss: 0.4303, Accuracy: 84.15%

Client 3 round 11 (before train) - Evaluate on 511 samples: Average loss: 0.4303, Accuracy: 84.15%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.415075				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.593567				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.452670				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.331473				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.578798				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.465114				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.454995				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.452029				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.418089				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.352521				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.322018				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.663852				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.542090				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.568320				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.455145				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.272029				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.609315				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.465203				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.402963				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.480734				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.553243				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.337660				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.416271				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.471932				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.449010				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.326740				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.292611				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.339102				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.397894				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.391040				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.362079				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.633396				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.584430				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.405278				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.394421				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.451149				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.449767				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.469827				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.514848				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.386232				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.676876				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.379537				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.546616				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.453027				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.241739				
 Client 3 round 11 returning params_prime of size 4800816  

Client 3 round 11 - Evaluate on 511 samples: Average loss: 0.4227, Accuracy: 83.95%

Client 3 round 12 (before train) - Evaluate on 511 samples: Average loss: 0.4227, Accuracy: 83.95%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.279182				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.480303				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.456360				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.441529				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.412200				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.411488				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.388702				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.480108				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.564531				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.448140				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.455934				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.316460				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.514239				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.334948				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.350912				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.483654				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.406982				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.366610				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.327575				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.454220				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.346001				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.367147				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.227523				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.331595				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.306124				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.374733				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.443740				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.323749				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.685219				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.608117				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.467817				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.332963				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.308260				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.314868				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.498232				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.327246				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.389850				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.347733				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.591479				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.580412				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.598711				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.575730				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.477452				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.296607				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.444198				
 Client 3 round 12 returning params_prime of size 4800816  

Client 3 round 12 - Evaluate on 511 samples: Average loss: 0.4185, Accuracy: 83.95%

Client 3 round 13 (before train) - Evaluate on 511 samples: Average loss: 0.4185, Accuracy: 83.95%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.518734				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.561884				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.498050				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.370934				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.400485				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.530478				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.500385				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.489071				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.366803				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.368416				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.620586				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.381750				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.410716				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.310032				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.305648				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.474190				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.649074				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.309347				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.540644				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.301942				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.484411				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.426337				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.464882				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.237408				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.396222				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.359686				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.529523				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.469468				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.405709				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.355921				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.596539				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.429485				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.303096				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.354569				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.561483				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.339815				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.592245				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.247221				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.445066				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.695234				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.418966				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.424519				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.359342				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.435508				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.301863				
 Client 3 round 13 returning params_prime of size 4800816  

Client 3 round 13 - Evaluate on 511 samples: Average loss: 0.4138, Accuracy: 84.34%

Client 3 round 14 (before train) - Evaluate on 511 samples: Average loss: 0.4138, Accuracy: 84.34%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.380162				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.367504				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.385895				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.657377				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.440662				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.522360				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.340354				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.417236				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.371423				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.554747				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.628394				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.333400				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.618473				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.357234				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.320842				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.322674				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.374348				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.266505				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.432621				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.661666				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.368799				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.370532				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.279615				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.478651				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.384828				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.339311				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.446285				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.509323				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.525804				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.391633				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.495541				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.294450				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.483768				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.386498				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.476819				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.742420				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.391926				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.447710				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.548754				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.395846				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.283765				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.329100				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.520635				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.321136				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.479763				
 Client 3 round 14 returning params_prime of size 4800816  

Client 3 round 14 - Evaluate on 511 samples: Average loss: 0.4096, Accuracy: 84.15%

Client 3 round 15 (before train) - Evaluate on 511 samples: Average loss: 0.4096, Accuracy: 84.15%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.317649				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.323114				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.387728				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.369461				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.270258				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.355246				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.518627				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.433674				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.322885				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.357114				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.424278				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.292147				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.670468				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.417593				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.527309				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.358906				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.420351				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.243222				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.392269				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.426319				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.366386				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.556510				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.597516				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.391095				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.378345				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.298092				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.457328				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.324494				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.484088				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.197963				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.425020				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.374474				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.275630				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.428417				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.295089				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.399079				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.344531				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.409334				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.558658				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.397930				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.396386				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.259388				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.461679				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.327895				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.444979				
 Client 3 round 15 returning params_prime of size 4800816  

Client 3 round 15 - Evaluate on 511 samples: Average loss: 0.4028, Accuracy: 84.34%

Client 3 round 16 (before train) - Evaluate on 511 samples: Average loss: 0.4028, Accuracy: 84.34%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.415085				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.326209				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.466812				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.615713				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.289237				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.421979				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.567747				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.337162				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.455269				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.373567				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.511876				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.383748				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.290134				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.428908				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.396281				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.354309				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.436607				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.382849				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.363755				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.371825				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.385717				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.422561				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.310926				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.389017				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.413660				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.286318				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.491378				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.330541				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.497150				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.313866				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.298816				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.480446				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.496118				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.473359				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.285737				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.521760				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.374253				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.461606				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.349911				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.498909				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.304425				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.404125				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.480234				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.394516				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.591755				
 Client 3 round 16 returning params_prime of size 4800816  

Client 3 round 16 - Evaluate on 511 samples: Average loss: 0.4015, Accuracy: 85.13%

Client 3 round 17 (before train) - Evaluate on 511 samples: Average loss: 0.4015, Accuracy: 85.13%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.211323				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.440765				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.567431				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.379439				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.461858				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.296498				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.517194				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.359554				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.322489				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.407419				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.499155				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.301250				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.531780				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.442475				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.294111				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.320114				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.467109				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.444735				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.325013				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.309469				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.323319				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.411165				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.432815				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.482066				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.669684				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.318994				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.369396				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.351547				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.512856				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.366473				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.446631				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.309629				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.424196				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.204303				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.538173				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.288064				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.450232				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.404062				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.686342				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.400004				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.398801				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.393467				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.448949				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.181360				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.226884				
 Client 3 round 17 returning params_prime of size 4800816  

Client 3 round 17 - Evaluate on 511 samples: Average loss: 0.3967, Accuracy: 84.15%

Client 3 round 18 (before train) - Evaluate on 511 samples: Average loss: 0.3967, Accuracy: 84.15%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.411007				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.364626				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.291242				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.386794				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.209172				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.314085				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.377732				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.268132				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.293325				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.396384				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.549149				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.351577				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.524246				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.286079				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.415573				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.653319				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.314607				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.408374				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.439642				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.316248				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.441878				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.431385				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.357040				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.456171				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.438462				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.456666				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.455684				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.386503				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.319660				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.331868				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.769442				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.541564				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.348146				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.374890				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.336512				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.444374				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.283769				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.376077				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.454326				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.336801				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.408164				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.298758				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.214224				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.498318				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.477294				
 Client 3 round 18 returning params_prime of size 4800816  

Client 3 round 18 - Evaluate on 511 samples: Average loss: 0.3928, Accuracy: 85.71%

Client 3 round 19 (before train) - Evaluate on 511 samples: Average loss: 0.3928, Accuracy: 85.71%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.429209				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.260305				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.223975				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.344674				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.435345				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.299151				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.522256				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.390816				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.309333				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.468825				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.530494				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.283034				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.298663				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.448164				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.257883				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.341787				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.269062				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.536425				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.454840				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.313307				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.407651				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.417410				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.520602				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.564816				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.275143				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.418072				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.453751				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.303943				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.440922				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.378016				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.605044				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.332613				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.625624				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.410415				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.411629				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.630740				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.489290				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.402834				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.356859				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.504258				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.320125				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.433450				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.385357				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.359883				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.337277				
 Client 3 round 19 returning params_prime of size 4800816  

Client 3 round 19 - Evaluate on 511 samples: Average loss: 0.3895, Accuracy: 84.93%

Client 3 round 20 (before train) - Evaluate on 511 samples: Average loss: 0.3895, Accuracy: 84.93%

Training 5 epoch(s) w/ 93 mini-batches each

[client 3] Train Epoch: 0 [576/5952 (10%)] Loss: 0.264164				[client 3] Train Epoch: 0 [1216/5952 (20%)] Loss: 0.387495				[client 3] Train Epoch: 0 [1856/5952 (31%)] Loss: 0.276601				[client 3] Train Epoch: 0 [2496/5952 (42%)] Loss: 0.272793				[client 3] Train Epoch: 0 [3136/5952 (53%)] Loss: 0.271788				[client 3] Train Epoch: 0 [3776/5952 (63%)] Loss: 0.301301				[client 3] Train Epoch: 0 [4416/5952 (74%)] Loss: 0.281586				[client 3] Train Epoch: 0 [5056/5952 (85%)] Loss: 0.423200				[client 3] Train Epoch: 0 [5696/5952 (96%)] Loss: 0.301212				
[client 3] Train Epoch: 1 [576/5952 (10%)] Loss: 0.228696				[client 3] Train Epoch: 1 [1216/5952 (20%)] Loss: 0.447813				[client 3] Train Epoch: 1 [1856/5952 (31%)] Loss: 0.325052				[client 3] Train Epoch: 1 [2496/5952 (42%)] Loss: 0.487042				[client 3] Train Epoch: 1 [3136/5952 (53%)] Loss: 0.350143				[client 3] Train Epoch: 1 [3776/5952 (63%)] Loss: 0.276894				[client 3] Train Epoch: 1 [4416/5952 (74%)] Loss: 0.415887				[client 3] Train Epoch: 1 [5056/5952 (85%)] Loss: 0.533364				[client 3] Train Epoch: 1 [5696/5952 (96%)] Loss: 0.315621				
[client 3] Train Epoch: 2 [576/5952 (10%)] Loss: 0.587476				[client 3] Train Epoch: 2 [1216/5952 (20%)] Loss: 0.479980				[client 3] Train Epoch: 2 [1856/5952 (31%)] Loss: 0.472715				[client 3] Train Epoch: 2 [2496/5952 (42%)] Loss: 0.337728				[client 3] Train Epoch: 2 [3136/5952 (53%)] Loss: 0.377321				[client 3] Train Epoch: 2 [3776/5952 (63%)] Loss: 0.290721				[client 3] Train Epoch: 2 [4416/5952 (74%)] Loss: 0.407055				[client 3] Train Epoch: 2 [5056/5952 (85%)] Loss: 0.344733				[client 3] Train Epoch: 2 [5696/5952 (96%)] Loss: 0.335670				
[client 3] Train Epoch: 3 [576/5952 (10%)] Loss: 0.640229				[client 3] Train Epoch: 3 [1216/5952 (20%)] Loss: 0.390435				[client 3] Train Epoch: 3 [1856/5952 (31%)] Loss: 0.417428				[client 3] Train Epoch: 3 [2496/5952 (42%)] Loss: 0.287001				[client 3] Train Epoch: 3 [3136/5952 (53%)] Loss: 0.364596				[client 3] Train Epoch: 3 [3776/5952 (63%)] Loss: 0.309927				[client 3] Train Epoch: 3 [4416/5952 (74%)] Loss: 0.423127				[client 3] Train Epoch: 3 [5056/5952 (85%)] Loss: 0.352503				[client 3] Train Epoch: 3 [5696/5952 (96%)] Loss: 0.519023				
[client 3] Train Epoch: 4 [576/5952 (10%)] Loss: 0.403090				[client 3] Train Epoch: 4 [1216/5952 (20%)] Loss: 0.404156				[client 3] Train Epoch: 4 [1856/5952 (31%)] Loss: 0.457642				[client 3] Train Epoch: 4 [2496/5952 (42%)] Loss: 0.370027				[client 3] Train Epoch: 4 [3136/5952 (53%)] Loss: 0.385038				[client 3] Train Epoch: 4 [3776/5952 (63%)] Loss: 0.346420				[client 3] Train Epoch: 4 [4416/5952 (74%)] Loss: 0.505665				[client 3] Train Epoch: 4 [5056/5952 (85%)] Loss: 0.402005				[client 3] Train Epoch: 4 [5696/5952 (96%)] Loss: 0.457523				DEBUG flower 2022-04-19 16:20:39,556 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-04-19 16:20:39,557 | app.py:72 | Disconnect and shut down

 Client 3 round 20 returning params_prime of size 4800816  

Client 3 round 20 - Evaluate on 511 samples: Average loss: 0.3869, Accuracy: 85.13%

